{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariuss811/WakeWord/blob/main/notebooks/easy_training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11cNiLqvWC6"
      },
      "source": [
        "# üéØ Training a microWakeWord Model\n",
        "\n",
        "<div style=\"background-color: #f0f7fb; padding: 15px; border-radius: 10px; border-left: 5px solid #3498db; margin-bottom: 20px;\">\n",
        "    <h2 style=\"margin-top: 0; color: #3498db;\">Welcome to microWakeWord Training!</h2>\n",
        "    <p>This notebook steps you through training a basic microWakeWord model. It is intended as a <b>starting point</b> for users who want to create their own wake word model. You should use <b>Python 3.10</b> for the best experience.</p>\n",
        "    <p>The training process follows these main steps:</p>\n",
        "    <ol>\n",
        "        <li>Setup the environment and install dependencies</li>\n",
        "        <li>Generate wake word samples using text-to-speech</li>\n",
        "        <li>Download and prepare background audio for training</li>\n",
        "        <li>Set up audio augmentation to create robust training data</li>\n",
        "        <li>Configure and train the neural network model</li>\n",
        "        <li>Export the model for use with ESPHome</li>\n",
        "    </ol>\n",
        "</div>\n",
        "\n",
        "<div style=\"background-color: #fff3cd; padding: 15px; border-radius: 10px; border-left: 5px solid #f0ad4e; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #8a6d3b;\">‚ö†Ô∏è Important Note</h3>\n",
        "    <p>The model generated will most likely not be usable for everyday use without experimentation; it may be difficult to trigger or falsely activate too frequently. You will most likely have to experiment with many different settings to obtain a decent model!</p>\n",
        "</div>\n",
        "\n",
        "At the end of this notebook, you will be able to download a tflite file. To use this in ESPHome, you need to write a model manifest JSON file. See the [ESPHome documentation](https://esphome.io/components/micro_wake_word) for the details and the [model repo](https://github.com/esphome/micro-wake-word-models/tree/main/models/v2) for examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjc5l-KG5R6t"
      },
      "source": [
        "## üì¶ Step 1: Setup Environment\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Installs all necessary dependencies for microWakeWord training, including platform-specific requirements.</p>\n",
        "    <p><b>Expected time:</b> 2-5 minutes depending on your internet connection</p>\n",
        "    <p><b>Note:</b> You may need to restart your notebook kernel after this step completes.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFf6511E65ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c24a452-7464-4360-f1cb-5b479162a9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f\n",
            "  Cloning https://github.com/whatsnowplaying/audio-metadata (to revision d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f) to /tmp/pip-req-build-ml6vacu6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/whatsnowplaying/audio-metadata /tmp/pip-req-build-ml6vacu6\n",
            "  Running command git rev-parse -q --verify 'sha^d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
            "  Running command git fetch -q https://github.com/whatsnowplaying/audio-metadata d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f\n",
            "  Running command git checkout -q d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f\n",
            "  Resolved https://github.com/whatsnowplaying/audio-metadata to commit d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=18.2 in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (25.3.0)\n",
            "Requirement already satisfied: bidict==0.* in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (0.23.1)\n",
            "Requirement already satisfied: bitstruct<9.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (8.21.0)\n",
            "Requirement already satisfied: more-itertools<9.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (8.14.0)\n",
            "Requirement already satisfied: pprintpp==0.* in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (0.4.0)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from audio-metadata==0.12.0) (1.17.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets) (3.0.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.9.0.post0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (1.17.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Cloning into 'microWakeWord'...\n",
            "remote: Enumerating objects: 388, done.\u001b[K\n",
            "remote: Counting objects: 100% (388/388), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 388 (delta 215), reused 318 (delta 158), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (388/388), 673.30 KiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (215/215), done.\n"
          ]
        }
      ],
      "source": [
        "# Installs microWakeWord. Be sure to restart the session after this is finished.\n",
        "import platform\n",
        "\n",
        "if platform.system() == \"Darwin\":\n",
        "    # `pymicro-features` is installed from a fork to support building on macOS\n",
        "    !pip install 'git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version'\n",
        "\n",
        "# `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter\n",
        "!pip install 'git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f'\n",
        "\n",
        "# Install ipywidgets for interactive notebook elements\n",
        "!pip install ipywidgets\n",
        "\n",
        "#!git clone https://github.com/kahrendt/microWakeWord\n",
        "!git clone https://github.com/BigPappy098/microWakeWord\n",
        "\n",
        "!pip install -e ./microWakeWord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYBPNCLx5R6v"
      },
      "source": [
        "## üîä Step 2: Generate Wake Word Samples\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Generates a single sample of your wake word using text-to-speech so you can verify it sounds correct.</p>\n",
        "    <p><b>Key parameter to modify:</b></p>\n",
        "    <ul>\n",
        "        <li><code>target_word</code> - Set this to your desired wake word (use underscores instead of spaces)</li>\n",
        "    </ul>\n",
        "    <p><b>Tips:</b></p>\n",
        "    <ul>\n",
        "        <li>Try phonetic spellings for better pronunciation (e.g., \"hey_komputer\" instead of \"hey_computer\")</li>\n",
        "        <li>Listen to the generated sample to verify it sounds correct before proceeding</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dEluu7nL7ywd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "3e6068b6-c4c3-4b30-fa20-3ac907692eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:__main__:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "INFO:__main__:Successfully loaded the model\n",
            "DEBUG:__main__:CUDA available, using GPU\n",
            "DEBUG:__main__:Batch 1/1 complete\n",
            "INFO:__main__:Done\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,UklGRiRuAABXQVZFZm10IBAAAAABAAEAIlYAAESsAAACABAAZGF0YQBuAACRAI4AbwB0AGYAXgBXAF8AUwBKAEwAUAA4AC4ALwAfACYALQApACQAJwAVABMAFQANAA8AFQAQABUA+v8KAAUABQAKAAcAGAAEAA8ACwADAAkABwAGAAEAAQAIAAMAEwD2/wsACQAJABMAFgAjACQAJAAaACIAHQAgABkAIgAgADIAHQA9ACcAPQA6ADYAQwAtAEAAMwA7AC8APQAqAEkANABGAEMAOwBEAEIASwBRAEYARwBOAEIATwBAAEwAQgBJAEwATgBGAFYASQBZAEYAUQBdAE4ASQBFAEYARQBEAFAASwA+AEcANwBCADYAQwAsADYAHwAtABkAKAAZAC8AGwAlACoAGgA0AB0ATgAfAFEAKwBOAEcAQwA2AEEAPQAZACoACwAIAPr/8//g/9r/xP/r/8X/w/+l/6n/n/+U/6j/q/+s/7D/vP/R/+7/DQAzADYAWgBcAHIAbACFAIUApwCpALoAuwDLALwAxACyALMArwC9AL0AuACwALwAxgDLANoAswAAAXYANwFsACMBMwCsAIECywI5BH0DnwPQA9ADiwKkArYBbwFgAJgAqADt//sAewCIAHcAmQDp/zsALQA7ADcAUwDMALwAAAH1AAwBHAESAfcAGAETAS0BRgE/AWMBeQGYAa8BrAGtAaoBrQG1AaEBoAGtAcsBxwG2AdcB7gHmAfYBCAIBAgYCCAIQAgMC/gH7Af4B/QHZAQkCFgINAgQCBAIxAiUCPQJiAk8CNAJQAjcCJQIoAhgC2gGtAZgBdwFFARQBGwHnAL4AkACAAH8AbQBhAGQAUwA6ADUAOQAXAAIA5//j/+j/q/+k/6L/iP9m/1X/SP9H/zb/Of8y/zP/Uf9M/zv/UP9W/0v/Tf9J/2D/Xv9x/37/bf9l/2X/b/90/3b/dv9x/0v/Ov83/x7/DP8G//r+7P7M/sL+y/6x/qj+pv6h/q7+sv60/sX+0v7g/uD++v7z/v3+D//7/vD+7v7x/uX+1v7C/sT+uv7R/q3+nf6l/p/+lv6U/rr+tv67/rf+uP6f/p/+n/6C/pP+iP50/ob+ev52/nj+df56/oX+kP6N/qD+lf6d/rD+n/6s/qL+m/6o/p/+of6b/rz+vv7N/u3+6v4G/wT/DP8Q/xX/Ef/8/gb/Bv/5/gH/+/76/vr++v7y/uX+9v4A///+Af8V/xz/Gv8c/xv/JP8d/wr/Ff8L/xL/IP8R/w//Bf8F/x7//v4A/x//EP8R/+j+4v7j/tH+1v77/u3+7/7//vf+Af8H/xL/Ef8p/yr/LP8Q/yL/Jv8s/0b/Mv8t/zT/Kf8Z/xn/Ev8J/w3/E//w/gb/D/8U/yn/Hf8P/xv/Fv8Z/yL/Gv8h/wL/BP8X/x3/Ev8Y/yT/Mv9O/2D/Wf9J/13/U/9E/zf/QP9W/1f/Y/9c/1z/U/8q/y3/TP9N/0v/Uf9W/y//I/8O/xH/D/8B/yz/Nf9S/0r/Q/9Z/0L/Pv9h/1L/TP9d/3v/df91/5L/l/+o/6n/yv/J/9P/1f/O/+P/2//e/+//AAAOAP//7f/2//n/8P/Y/9T/yP+8/7z/v//N/+H/5v/7/wgAEwAOABUAJwAqADgAJwAvAD4ARwBFAF0AbQB2AIkAgACRAJcAkACYAJQAfQCDAIAAbwB5AH8AiQCiAJMAjgCRAIkAaABcAFwAUwBdAFEAYABjAHMAbQCIAJ4ApADCALsAwQCpAJ8AnQCpALQAxQDOANMA5gDWAN0A4QDKALcApACfAJcAeQBmAIgAnwChAK8AvwC8ALkA0QDZAM0A3wDpAN8A/QAJARsBMgE0AVQBYQFkAXMBVQFmAWIBWwFiAVYBUwFWAVsBQAFJATsBQgFEAU0BWAFmAYgBkAHBAcYByAHhAdIByQHSAeIB3QHSAeAB4AHqAegB4wH1AeYB2gHgAdsB8gHrAfMB7wHiAewB6AHRAaoBrwGpAaIBmQGlAZIBiAGYAaoBvwHVAdgB5AEAAv8BGwIOAhECLwIoAhsCJgIiAiACIwIwAjICSQJIAkECNQIlAjgCHgINAgACDgIHAhACJwIqAjICJwIaAiMCEgIDAhYCGwIgAioCKAIoAj4CTgJLAlgCfwKXAp8ClgKlAqgClgKCAncCfgJtAmwCbgJkAnYCbgJHAjwCKwIbAgwC/wEBAvQBDQIyAiICFAL6AeUB3QHUAcgBxQG8AbQBoQGiAaMBkwG2Ac8B5gHVAdQBxQHHAcoBywHoAeUB3gG+AaUBjQGhAawBoQGrAY4BjAGlAY4BawFZAU0BSgFvAW8BlQF+AV4BhwGEAXoBcwF+AYEBjgGbAbABzQHqAdsBCgIqAkQCVgI2AlMCHwLzAfYBBQINAgsCJgIvAhcC7AHnAfkBBQL8Ad0B1gHqAeoBwgG6Ac4BuQGZAZ8BkwFvAVMBBQHLALoArACdAIwAggByAKYA0gDLAMgA1wDkAOIAvACaAKwArACyAJ0AvQDbANcA7QD/ACgBPQEdARMBJAEzAQEB7ABCATgBLQErAT4BTAEvATMBKQHfAKMApwCJAIgAqgCyALEA5wD7ANYA6wAgAfsA4wA+AUMBJAFDATwBQAFpAYYBnQGZAbYBswG7AdcB0gHOAaMBZwFNAeAATQAzADwAbgAwAPz/DwD3/8D/tP/I/93//f80AHMAQAAMAB4AhACCAFQAXAB6AIAATQA5AP//7v/o/+X/DwAIANb/1v8JAPP/6f/f/3H/UP9X/5//ov8J/2P/EADZ/7//4f8SAP7/vP8cAEQAOwD0/8v/CQA0ABcA+v9dAK4AqACbALYAqACMAF8AXgBcAEwAHgDZ/zAAegBBAGYAwAA2ALf/p/+s/8z/rf8//zL/vv+n/yz/nv/t/27/Nf9+/8n/2v+5/6X/jf98/7D/xv8PACIAuP9o/5n/Zv/q/rf+L/+z/yT/dv5g/oj+/f3D/Zv9y/0x/kX+Xf4r/iX+gv72/un+3P5i/3j/x/6M/ib/dv8I/v/98P9SAA4AZAAlANn/9v8KAAoA8/8AAPj+pP66/w0A0v+u/4n/6/7L/kf+cf5q/qX9pv4U/8L+ov7M/rT+4v6B/uX9sv3S/Vf+Lv4B/hj/bv9X/pz+AQAiAMH+D//j/wL/If09/XP9Qf2Q/eL9//0F/qD+j/5Z/rz9UP5f/sD9RP76/Wv9g/3K/Rj+Av6o/Vr+lv83/0P9a/xP/tT9G/yx/CT+//2v/Yz90v0i/2/9sfy5/C/+2v1j/ZX+JP6J/Tr9Gv0O/ef+fP1x/Rv+5Pxp/Zz9FP2g/Xv/jP+T/aX+CAEU/879yP3q/RH/jP7C+3L6yfyv/f77lPuG/BD9y/tG+0X9yPz3+yD+8P2Z/ef9j/1y/RP95fuc+kz60/sA/Yj8o/wF/pn+zfz/+nj8Yf/Y/Ar8Sv3A/hf9zvoc/uT+kP3H/Ob9+v5c/Ej7Lfqa+839ZPr7+mf+Z/8g/TH8m/8aAI769Ppu/nr9RvpB/Nj+1v4P/SX7V/9m/rX7oPxh/9b9PPpc+qD9Bv3K+YD8owDO+xP6kv9b/IT5+Put/J795f0L+z/8Tv5c+6r70f1t/sT8yfl0/A39Ivwn/Rv/gv3g+ef6/AEf/yr32vpIAbH+5/hv/Ez/df3++Jn4bP0+/z367PrN/Yj9m/xg+7f9Xv5Q/dD85P5+/rv79fyE/dP87f0X/EP7zPxJ/Wb/z/rb+3H/cPt1+lb9J/4C/978o/px/XL9N/8a/A38kgA/An/6JvzZADr9TPtB/aD8xvmH+S391AGd+1P9B/+L/nX7b/pb+z/7yv1n/GT6Qv2pAJz9bfwZAFH+4/2o/4H9+foD+sH+fgCZ/Xz84f/q/pT62fuw/iT82vnA+8P7ivrG/KP9ufkK/b8CkPyS+V7+pvzf+8r9jPtW/Fv9gP2fADb/HgPPA93+/ALmBeX/4/cEAaoEmf/U+4b7iwKbAnv+jvzRAqYA5fgt+fMAy/r8+Gj+K/rv+U/6sftG/AP/4Puf+tz95/2M+iv9wvv3/hIGp/3x/J0CvAEUALj8MPwcBr//TPYA/YgGoQOg9ub4tQAEA/j41faX/GUAKgBH+UsB2P90+YD7F/0+AVr9ifkfAUb/hPhi/O0AegBP+l/2Ev9WBo79xvYoBXQCp/na/l0AxgOH+ccAUgyt/l72QQRcCzf7qfbUAXMGlP4k9cf6wwkoATX2+/yvBYUAu/JM/csIrAHN8sEDrwcL9hH8MAHGAYv5av3SADIDSvxu+04Auv4zAJIClP1K+2sKzAPI/D74GQImCSv8CfgXAlgBl/eiAPkCoP4j+63/qQPDBXT4L/sMCNsEFfmq+y8MCv7Q/gH8tf0aBxn7of/iApz3xwQwBgj7AAIqAn8ISgLa86n+Jgp//wb7zQMxB2j4k/ucC5H6dvu7DW8C5vzc+xf5lwdW/B35CQeUB3v/jfiGBBIC5PhQCLsC+Pf2/YX+Rgt6+xv2HQ6RBej8EQJC/7EEWAGyAtf+TPtOB3v+z/9QCCj+Wfu4B2n/Avs3BQYE+/dVBQwMcv3TAWH8ygFPECv1JPoeDzj6RfsUBpEDRPso//0I+v20/ZoG7ADABAQAr/xiBVwIzAEy/F0CVv8kBG//lfqYAfr8yAq4AcD1QgnbCL36PwGgCOMB9fumCMYD2PDyBcQMcvul9xAK/wHd+/4MwPh89AMQAAbG9HgI1wCD+MoY1/q58LsRAP+c+RcC9P/LBr0DLPQODCD+NPh0D4UAYfUa/40Off9a+BEBbhBf9pXyFxOOBgr1/wLkErv3jP7BD0//PwA9/Z0GEhEx8030AiAf/KbqCxZSDJjtDgFeC5wBwfxs64clqvl82DMh0RDY5LoB2BA5/J4L+vt4+okQ8AOP+A0EFATaCdUD0PaYAIgUpv+c8JoIvBjk89jw/RX1Bm7y6PymGQMDnu+QBN8TivKz+DMW3wYj8MP3/w/IDCvt7QHjE673OwKTAKv+/f+JCaf4OwKLD3P9B/O9DG8Ahv4ECKP2owfJA7YCavp5CvEBAfzbCaIE4/ijBsAANwOe/+IDMgXQ8voLag8P7lr2BRz2+I/5awu/BDjwNAsCFAXqhAJbF/jtOAMlGFPx5/3IERgEkPeHB8IJvvhDAOsKAfY/DOn4nQD5E7vwsfwMFJ0EzfBBCqkK3+0DC+cPGO0dCzQPCvwd+j4MRQaSAVL6HvwzEN0BpvKOCvgVUO+08KIagxRC23//Lils8p/wZxt/+/r7tQqj/lEBUgrw/nX5KxKA/Jz9mAYrCj4CdfvICMkFz/h3CYD+V/NPFjf+5fnjAZoFhgodAyP3ywstC2/06g129zEJOgfw78AQUwrU/QgEXQOw/j4Grw8i7DwGHRp35EcN+Rfl8a/z3g7bFA3xTu+oFz8PgvsF8gEMhhFL7BcKCQ12+tf25hjKC3rlwwjBGvoAoeVOGeUSt+atCGoN5wI491IKAwhWAHH5wQaeAl/1vhDa+0D+QhA89Y8ADxRH/AsELvnrD7wBhe+vD9YRrPb18W8hmf0q5NIU8hJx+Xr4SgugAagAeA34/NH6TAw6A2jttRuT+B7wkhpXALbzFwKOD/T/jwBfAfn+ogiYDAfrBguHFqTvzP29E40Mw+nbA+YatPYl8iEc3gKt9DAIPQxO9c8Igg6U7hwV6fy098cTSvqf9W0TGg3K4J4G7R1u7EL8vxfVAOnqOBdRCH3qEQwCDPPxPwyuDCHxgwugDgj3h/kcHYf0XvEdHvj+fPXGE0kCB/VvFT7/7vekFfj92/ntCLYGxPalD234Wvo+Ge3zxv1WBvcPv+6u++UeWPPK8JoaWgG47y8JBgtCB7f3yPiLFT0EGPBfCLIbQvHb9D0gOPIv/FgW6wHC9SkHRAMEB9r+ngLvBd4E4Aq89wMHUwCj+Y0KCgeX+gr4dQiTFNjy6vSgGGUIPes/DKEPiPLa9iUi3v0L6IAZZQRh9ZMG9Q1n90zyaB3pBFbhSRO6CjbuNAFdEt/X8yIuNTCmMxOPRxDRqvsLB8ELtgQB7FsQVQiV/WL8MhHH+v0FJQUz97MLMP25/Rb/DQ4f/dvylBRk/Z755wRO/8IErP3I/coOE/agAIEQV+4lBygNWfQTBNn9qQjyAzHwPAecDMj60faaFIn6xfgHCfUD6APt/3T1YhLqBSPlKxrZ+xP8lBEu+Uz3cQl9E1rruvVHGT0FefHw+mUTqQXS6Z8GnhYu8Dz9rgrY+f4Gc/x3ADUUQeswBmEQpfLdCOX8AQZjAcT+uPdmC0z8q/mCDCsEg/Ge/4EaBOxP+wUTGP787AUUIwUT9xr9OhA79971tRo/8zIEyPfYDsAEfejKGXEIyuNSCv4ZJO4p+WobmPI9ARoCs/VYGUL0ufQRDWoWpeC893QrRex14bEj9QIS7KgNXPBuGz73O+eUH84KHeCFC00PdPR1BgT8pRAX76kSgPbO79kpTuTo8C01BOJz6wAy9t/oAhoZqebE/hMgreaB6Skidg5n0esR8hNV7WoeetnYBTslzd609RsmX+zW81wQvAg19EcGCAOP7iYYvgLi7y391Bo67MX0FBb+/j35FQTVCCf4ef7KBzLzOgvy+974kQsn+NwDVwD2/CUJDv2n8I4d6fEs/W/2ph8w9WXoYifU6r3/NAbMHaXYX/A/MhX26NoRGO8WjOxt9ugL/gRp8QsHtP+n+ToICwQ7DNjwGQppAy7tdBRX+Hfuvg5RDiXuNQUKAiv29AsB+lr2Ug71+nIE+P0E9/AYdfG97godIgNQ5DIW3gxr4j0KHBOo7OT+RhPj7kf/fQa7Adv/O/aHC9wGEPAEAUEUkvAJAfICEvNqDyz5vP5/DRT14P1ZCJ0BDfb+CVgJPOzMDNARruEW+58mJfKQ6tgUJQAb9nT9KQyrAinzdQJpB1cJUe/y/WkVg/nt8XkG/Ap18lP1Phm/AHHivR+G/V7hbR/gCR7YchpiG0nAqR77JvrOfv7TKc3fZP2BGz3mIwrQ/gQEXgSO73MNvQ3z7FAKDwvP5s4Pyfzn9Q4W2On2Cf0Emv/9AxrtPxV+Bbfr+QleBmb3khKu7T0BXxaa7KgJIQhd5pgQngmm4xsVpwAV6WMOFQkUCEbCvUMMHfOZuk7W+K/YpTNQ6fXyViCu8QAARgRAALcEn/h4EaDqJwd2EPzuxf4ABcUEFPV1DDL3vvYdEu0AW/XjAWAIMPI+AfgML+xF/eof3ebn/soTBfkm9W4TxP3K8koJdQYi9sIHIA004fEMPxQP60D5sBNm2a8rQ/V9A4nsr/UyW3qth/nbPP3XXw109m7pbDnTz3MFvRqJ5tcJngA4AdP4bAIICNL42f/FD7Dy/widBQrvwguZAFT6kQIm+IsEOwxF87kABxAK9jr/ZAPFAZH/1fqi/WsF6P7u96gEKgMY9UEANhCo6lIJSf/A/RYH1vRTDL37rALtCNDzRPXFHNTt3QFWFUPoTQzt+Lb/mAbG+UkIY/tjAnkAE/LXD6j7TOm2Jv7qX+UYKbfz+PM6BLoPQfze8xwbae59+T4eZPOS7YMUm/lKBDEEIf4QA5H3shU36E3+eQ5I9S37sg/E7lv5ORUQ9AH1MgSwD4fptQ0MA7XvcRM1AdP34wVZD2b2zvcYHZX22OvuFmoIheTpBkEY6eKmA0MMv/QBDwz3M/uOGB7vP/7yCQ34YhTD8XT1IRO09uH4MvjnFBICKOCBFhcGifDsB3371QYQCIP4egn88RkOIQfx6cwRjAEr5dcR1ANq5C8k7uvG+QwQRv0h8wAEBBfk5xwD3RHUAFXnghDZDBHoewkL/sr6GAxy/EH2n/6zGDDyOus7GdgSINRzCl0hwOYpAvX5dBId+hPxrgzY+j38W/q4AkoNzu6iA4ML0fSCCmMBZOdQFI8G7OScA+wDphrB4UT5ux268HzzIQjqBBACRPAk/UYfquWMFszx3PqjHZrf9gR+CkL67v/qGbbniA5dFUTYzwQDFpf5f+KEIxEOpONm/a4kmO2m+6obge7P/2Xxoxi/7sP2+gI6AcX70gtj7jwKJRAU78kMbveSCRDz+R0S5cQKIxKK9QDyqiPDHEvm/SHGB3bxhwJ5IkzvSwKXAK8NXu3o9tEPlvRU9yjx7BXj5azwBRxH7QLo4BrJ8Grz9hG69Q7yDAgQC2P0RwynAWsH3wzd6gMvugR48n4UgPzXD4P2p/diCuQJjuPYF8EM0+N0C+UCPQAX/1P7aQk7DknyHwU79K/9ghUe5zMK8BQh6qYMSwsT8esDrRYa9e36pBWf4lAHIQ5x72P9kgos/gTwPQzkB1r6sfwjA0j5uQRUAab37QK+/jX8bwGjASH8O/aYC1P/WgHfCVLytBTKCJrrggtiB3/+rRJ7+U0IJQs++Xb+pgiA/fHn4xhRAmTo3QLRDpL6b/Ky/wYFWvy46IALvgEf9Q4HmBBR92b2jA3FBsPwJAI/Dg/yfQwEAMH5tgnt+hoEvAd18QcLWwrB+BEAtQLwCH/0PgEdCZzugwnT/QnpwAQ3+Er8yfi39Zr6FAT39Wr56ATK8xsCFPpe/937o/yC9kP7If9M8usG7wJ2+AD0VwWF/zX5GwT9AQcBCAgTAmn++gepB0oDwPsqCD78jvnh/aH+ove8+hECkP3o+c/zvQLaBfX2kPggAwD4K/vG+Cb8t/ud9l8C1Po97bMGYAKO72X/JwVPArD4+P5bAuT8cgFpBYT7Vv/U+xv/kvru/IEBDPkLBJH6DvsGAqr+7vaDAbP7jvM8+Nn3Ofss+Fj50/tw+2X1Vf1999z+MP5i/HL70/ZgA5j6RP1BBWcGrP4W+Y7/GQdy+r4Dggi3AMH9ufmEBJsAevwo/8EG/vwB/Zj6l/m2/9/9Qv24+hf+3fye/Mj4KP+N/Pf9Zf++/skBV/3zAh0DKPk7/Mf/LfUT/Uv5zvpR/6r4yfnX/WH6wfkfAuv56vsNAdn8rfm9/EAACgPD/xwElARu+10DBgGc/4IB8/0dApb81/mT/Uz8hf9JAIP7PPcr+D35i/fQ9Yr1AfiF9zH2KvZV+Ff7EPlE+g39SP2D/moAdP+A/nP/IP/xAJgAU/4yAYIC1P/7/8wA2gDj/RT/RAII/4H+lv3/+6D9lfwq/Iv70voI+xD6Fvq8+1P7+PlX+Yr7vv7W+g36Zf1H/sT96/3f/rH+FwBZAGcAxgC9AJMBRAB2AH4CEACb/nj/D/9/AZz+Zfo//NT8y/oV+4/6FfnD+lP6sPmF+rr7Q/xZ/Kr6n/o1/Hn8u/zv/Nz8Gf7z/BH8qPs9+/D8Tfv0+cf7ev6j/AH7TP3s/8n+4f6u/f/7Bfy2+3b78/tu/br8KPyt+rb7Kvzh/BH9wvpd+hL7B/ol/Z/95fuI/+r9ofyW/Y79CP7+/XH+lv+U/X39SQBK/9T+g/9a/8f+Iv4S/g7/O/+//10B8f8Y/2EA1gDJAF0AGQEYAWb/DAA2/9j+8QCQAFH/Mf45/n/+Tf4//Rb+HACk/679Xfwq/rP+vv3p/kr+Rf5W/q38k/sb/I/8A/zx+qz6yPoH+cX4FPk1+ij5Nvg2+DH5sfk8+VH4Bfk9+qj47PdD+Hn4efji9wL34fmh+Qv5wvoW+0r6Nfv6+lP7pPvH+7r85fxX/jj+B/8FAd0BWwGxAg4EZgWdBXYGTweOCAIJpQkbCmkK6Qv4C7gLAwsUC6YLzQuiCvYMmw1/DcENuww+DQIO4w2BDZENZw1RDMwL4ApsCv4JgQh7B44EJwRAAQj/Kv7G+jz4J/Tm8DztSupQ6GDl/+Jn3yDcQ9g81XLTx9CWzabJq8Ztww3Bor+nv7bD0MY3y5DQjtW73MXhMeY26g7tA++28b7ztfdl/LsBswf/CtUNug7hEW0SzxBoD2oNVA7KDNUMwA0uEFwTeRKXEtsR8xFXETsQQxF9EZ8RwBKXFTYZPB4fJEcoKyxyLbwt6S7DLiswHTJBMocvtC1HLogvrC3XKikq3SYTI0UfSx1IHeoaVxi9FpQVvhN/EUAQAg8lDbcJPwbwArT/Jvxa+KrzQO1X5rzeg9le0vHJTsAPtjauBaYcn5KWbo8NhgGA04jVnb+3E9D24ZTzewrnFpQcQCOmI90idB+AFjwTaRKhFkwebyIPIXAYwg89Blr8mu9O5mPhQt6B3Y3cnuMn7p356QF4Aq8BjP+p/+sARANMB+ALkRKtGOEgrCqhNaNAbEeZR0tBaTrCNXYy/S51KqsnIya/IlkgtR8GIGgfJxqCE04NgggKBmoGMws0DnIOkhAEFPIXgxofHbshEiQVIYgd9h0/HzYgfiH5Ik8kyiHPHfga8RpBG2gZzhgRF/0RfAyZCPoERgFQ+0vzMOoe4O3WC89Fx0XAZrnOsfyqMqWooYegQZ0klrGOxpU/sqrVnfLnCKkaNiqkNhA6MTz3N5UvfCOKD44BOvte/cMFqwfeAsH5o+4K5uzf0tnh1AHV29HD0LPUbd0d8bMB4gsMESYPTQ80EvEXqh2qIWUjwiEEIZcfmiRrLhA1tDWxLfAkxx0vGDwWHRb0FKoPYgkXB/8KlQ7UEm4aOhwQGUITDRKyF/4ZVhnzGHoYERhIGNwbOyEcJsAoICgqJiojKSIWImsi6CGJH7cdRhz3GvQatRslHBYa5RUSEscOXwweCUwF0f8q+yn1RO9M6ffgaNlwz2/G1b0EtKKs36QKoXyhSqDqntSX6o/dkuWp28ju5qEEBhu/MghDfUgaStNEYTpnKTIQcPIi29vUptd621Lb1Ni+2LzXFdc+1uvYNdyF3J/eR+EV7PT86g3oHsIoqi2lLYospSwfK2opGCLQGiYWpxEFEg4UkxrAIC0f8RmAFJsUCBfsFpkTBxFHEb8SlBTnF6MgSCjoLDguByylKSgnJSdyJ8YjLxy7FPsTXBVqFyoahxvsIB0iSCAyH6Adah9NHoUatReqFV4UQhTlFekXPRgOFvITchEtDQMI/QNuAP/5W++X5LzaHdM1zzjIp7/ltMSn7p0JmfqVpJIRj+eHwIPFkHyss9KK+1MaCzRuSixaB10iV1JJazK7F8v1XNj6xf28GsDixtPKy8u2yjrMIdBr0j3UA9nG3rDlD+9Z+voLZSBDMHg67DtMOIgzbSxDJh8ebhPoCTwBhv7z/zsDqgnpERkZmBpFGqgaYx2nHyQenRwFG8UZOBnrGUce6iF+IsEiVCE9H04bbxfnFkgVehG8D5EQUBN6F0Ib2yBqJgwolCi/KRQq3ieRJAMiwB6GGR8Tmw/kDnoN+gubC28MeAx8C+0MEA/OEKAQng6eDBMIogEW+6jzhurl3enODL8QryajVJkzkpKP7o20jnSPzI0kjZGXh7A+1ff8uBlVM6dJGVitXuBUykG0K8kNDu3WzD+z+6esp5Os/LRuvI3D384m2lbkJuye8oP5r/2gAdsI/xNFIU0rHC9KLZQoKyIVGpQSOArnAJT4UPOu8zb4L/8bCqkXQSC0JXQoNyv9LmYuzivLJXUeZBmMFGsTDxMaEQ8SEhDFDX8LUgqVDiQRwRFSEpMVgRo1H5UmhixOM/01ZjSoMyMuJijVIXsaxhNCDLMFwAIOA58F9QnRDnsUPhjjGRIciR3iHlYdcBlNFSYOFgY2/+j3HO/r4X/U98QEtyyvx6SWnwScz5VvlfiVDJUqlrCWF59stuXX7PmkGo43PUrsVcJTbEXiMCYWkffM16a6RabtnkKjJ652u3XH0NFB3AjmE+4L8zD3XPua/7MEKwtvFUQiCyxXLpApSyGSF+AOzwQc+yz0XO6S7tTz2PsgCXcXASbgMRA1UTTEMSEwui06J8gfzRd+EccOtw2DDewN4Qz6C2cLkwhEBhMJfg76FEoaTh1FJHgrHzF3NrQ3oTVpMf0r0iRBHKsUIA8NC7MGFQPgArsFqwr0D0kVCxqiHIUdFB7CHZkcrhzzG+Ua1hYfEUINdAfh/vbz8+Ui2j/O9cHGt3et/6Z0oXWfDqIgo+qlxaf9oZSe7aFssZDNde2QCnQj/TmQRlFJHT++KcIQI/Xa1d22HaCplSSa+qkOulfJJdhR5BjxpPrw/r0CngR7BUIJ8Qx/FMgfvynQLwYtiiOoGvEReAhz/s/0n+6D7e3xevpdB3kWEiY/Mg053TmKNcYwjyyAJqcejhVBDakJpwi8Cc0KoQooCr0JCQrqCT8KEw9cF1sfASV0KrMx4TidPf48uzi7McMnjB1TEyMJ3wPFANf//ADKAn4Ifw+WFkMbdx4KIE0gzyDXHxcf+BwqGw0apBYcEhwM4QaZAMH0+eea21fRJcqiwQu4Zq8EqXCl+KWkqB+nLKVXoSiYUprQp3rBkObRBikh/zc/SHhLTUM0LxIRavI20u+xlprtjt+Q+59qszTErNRE5MjxivyHAHABswF+AsoD8gVsDJsUlB2fJGIjjhzAEu0JdAQv/Q31MPCQ8Gv20wEFEI0eAS7GObU+XT7HN68v+yfNHhUV/QlBAnH9qPxlAFEEawh6CwENOQ/EEsIWgxqkICYlbCgSLU4wkTWYObQ4zTSELtckwRufEpEKGwVOAs8BSgKyBMEJCBHTGQgioCUEJxYmdiRGIrYevhm8FDgRNQ7tC4oJ9QZwBYsB4Psc9HLqRuI82OnNosOHt/Kvhqomph6ndqVwpzSlVZxylzmZxas9yV/nFwQYHvo0wkXxSfA+OyjaDK3t3svTqpORtYS+iQ6cabDnxCfU9OJN8ir8xABeAToB8QC1AEYEUgxWFkQfxSNhITgabBAvBS397/Xv7oPtlPH8+38KkBpsK/c4IEEvQw0+fzTJKGMf8BazDrIHqwH6/9sApARNB+MH1Ac7Cd8LgA9fEzAb3yX/LHgzVTg4Ozs8LDowNbYsniADFVUMUAZfAdkAOQQdCEgMNRCsFcwcjCFPI7IkbSThIo0giB2DGnkYpRbxFQ8VFRGkDOoIQgVv/8b2vO4z55HgTNjtzGPDGLsps/auUKv8pkKl/KHHm+qTSJHamwOzdNVW9xYUES6KPEtBvjpqJsgMovBg0mu1Sp/Xk5OVJaRWtkvH1NQd3W7kjemE7AHvp+9L8Zb2JP8+C5YYByKmJaIjixuyEPMFAfxQ9TvxEe868l77qAfVFlInJzUHPF08ATciLjcljh0xGC0VkhGeDrENPQyWC8YJZweWBDkC9QFxBFAJhxKGH8UtCzpWQAJCzj8tOtAyaCk5HgQV7wwjB6METgU8CZkO8hFLFIUVFhZGGEcaSR33H0IhjiLPI+8jASM4IdwechvgFb0OwwgFBA4Agv13+074XvJj61XkwNsQ1orNWcPuujuwaKmYp9KoQKeWoRqVLYtEkjWq0sx28a8NNSB0LiA2ozMEKMoSafQd2PW8e6fwnruhg66PwanQNNf22m7c9d435AjnXOiZ6/Hw6fpKCcQWSSArJRkjnRtGEWAFhPzN+Lb3mfnq/mEGNBEsHlcpkzFHNEkxdSqmI5oeihspGjAazhp9Gn8YLxXxEckMBQhVAxsBDAI5BgsOYRmjJZIweTgJPZY9gTlYM+EqJCOSG+sU2Q+nDVUNLw6oD3URCRPBE2ETBxMgFA8WrBkHHTEhayWYKF8qwim4JvohbBzyFfoOYQiKAq3/4f0q/Of5BvXn7/DpZuEw2DDM2cLEup6yRa9HquKpDapYo2uXFo0ljqWmKM0f8DQNnx44J3YsqSn0G9IJofKp2fbDYLXErSqyM8ACz9zaytzZ1X/OX8sAy6zP29ha4T3sNPsvC8wdniu0LCgm6hqnDAwCyPwu/OP/AgS3BxgOrhXhHEIj0Cf3JpYjJh+NG+0b2x/DIwwmzCXnIYodyBcVEQILGQfeAv4AlwJyB7wPcxnTIr8rHjJINFczVjLoMDotASksI1Md0hebEngOpAzJCj8JqghfCVALXQ6tEvAWPhsvHkAgYCJAJdgnCimjKK8m+iL1HVYYyhE0C8sFrAC2/WL7ePgC9jHyD+7w6J/gtNfuy4/CuLrjsRquI6qsquWr2ahOn6SUVJNAp4DKAO7jDBkedyUnKLci8xQxBWbv8tgfx/m7krcHvTfIG9OR2/7ZgNEqyUvGqMflzS7a4uVk8UkAXg4qHtUp5ifyHhsTsQY5AAkAeQRQC28Q1RKvFdQY1BokHLAcNBvLGVYYHxk9HVMkaiqQK50pXSOFHEkWPQ+uChIIIAW+BbIImg6PFj4dkyLzJlQpXCqSKl4s5S01LXkr5yYgIr4c7RY7EeIMHAkiBjMFWQaRCVUOOxMfF9AZ1xqhG78cVx/MIlwlJCfrJiglgyIMHhsYPBEeChgE3P+b/K75BfeV84bvgOok4g7Yhcy1w6S8Kbajs6ivL62Erdem7ZnojryPJqjm0Ab3gxCSHaIebhs8FVQIvPc45rTVqcdLw7nDlcrd1mfeR+AP2VXKIb6tuue/pMvK2o3otPVlA1EPJxztI5Yf4RR9CZEBOQECBk8NERYzG3UbJxr5GdUY4RbqFeIUdxUfF5UaWiGeKc8t7SxFJ9IfoRh4EioO7gsMDJsLVwzoDr8S5BbzGNoZJRw3Hn0hhSXZK8Ex7DMfMzovtyl7IjcaZxJ5DfkI+QaQB5kJaw3+EIYTohRhFBMTEBLuEjYWThpiH8ojUCZPJ1kmkiN6HpMXcRAUCrwFkQLZ/yT+JPzl+Nbzk+vw4tjYdNE5yxHF6b+nuUO2ZrK0slCvM6dVmgmQ+ZeMtPPbXf1cD4sUGhXkElgN4QCJ7xncrc+CxqPEGck50BLZ89z12qTP38OEvGq8oMh/1lPhku8m/dAKURiqHxsfDxgTDZoERwN5CP4Q7RhnHTcdABs0GZIYhxfTFv4WexjxGskdYiXgLOou5SwtJnUfrBrlFLsSaxERENgPOBBUFKMYKxs/G/8YVhgWG28ecCUvLVwznTbANB8xjy1QKDMfjhacD5EKFggCCJkKvg0XD38PXw/dDkMOIg5VELITAxcMG4kgRibyKFcoXSVtIDoaeRQYEP0NaAw7CksIbwUOAbn6XfIk6fngTtg/0UHJD8I3vPq3UrZWshWvOqlrnQmT+ZPsponLYe8TBYcMNQ5uCyQH9f8675/gHNWszBbMSNMW2uPgBOMT23TOaMCLt5u3+sFfzmjbg+o/96IEIxAeF6YYVRLGCEgBdAH4CMwSCxziIFIh5x78HDEbtBhGFucV9xf+G58h3yd5LV0vtCtgJM8e7xdiFG8T3hLlEwIVoxakGJYabxuFGaMVqxNIFDEc/iPpKGEvNTO8NDk0jC7hJxgiuBxzF/0StxAJEcESghMvEnkPmg31C4oLkAzqDQ4QoxNIF9cadR16HxQgHB9GHSYbCRnOF+4VOxV9FAETwg6bCGsCBvtO9OXrMOOl2unU+c5uycrCbLyJtnGzo7LGrVyoLJ6IjFqLY50Yv+PpxADcBZ4EHAPM/0D74u+i4jDa/Njc2QPcg99D3+7dhdjSyvK7lrW3tcTAxM+A3ybuZ/u0BXANoRKTEYsMtgYdBQIIOBJFH28odCuNJpkfohrfGHAYlhiPGWIcdiHqJnMrpi03LIwl0hxqFS8SExOjFv8ZiRxxHY4dSxwYGxkaCBfsFMAU+hWxHNUkGixqMk4ykC8AK7Ml+CBXHYka/hgMF1cVNxS4Ew8TrxDXDAwJ/QaiBtcIxAsiECkUVBaZF5sXFRjOGIoYfhdXFd0UmBUOF3YXSxbNE0MPmgnRAtr7pPRg7cflJt8Q2DDSLsxnxZ2+LrX4rASn7qIGn3aZV5JSkzioPsln6vD/iQAB+Vn0BPLF7Zrl49un1mXbsd5k32XgAN8L3cXVMchDvG+6NMMqz93c0Ojc8GT5lv4HAK0A5gDzAPoBSQSoCKwRkx3JJY0neSU+H1sa2xi1GR0dVSEyJYAo0CvZLJArbyd8H28YyBKREKMS9BW+G7oeih0HHGwZnhdyFkQSThJeFPcacCFtJL0pwyvILCYqgyPXHogfJx+zHD4beBqHGxIbcxcdE+8O0wuACIIGhwexCR0NdxDxEOIPFw97D/cPSw9dDwAQoBI2FT8XjxjoF60U8w8aDMcH1wJm/r742PMa7zDo8ODb2MTQ4MjVwQS7hLRPr0KrSKcpoZiZLJXCnau2ntNf6qnzi+/S62nrY+tA5yHhstuH2x7haeJJ46Tia+Dl2kbQk8VQwPbEU8+S2Djh3ej/7Xnz8PWi9tb3gPjp+Zf8VgJsC8EVAh9MI0YiECC+HZUc6hzDHrkhYSUcKM8pGyt6K/0oPCP6G88VuRP0FEcYGBv8HPocjBwBG1QajxgPF4IW5hbTGqMetiIxJjAoDii9JeUheh+dHtkdNh25G98ZcRn9GAgYjhWFEY8N6gqHCNsH2gi/Ck4NPA4ODhQNNAwVDMgLwAxTDpgPaxHBEkMU1RQJFHYRjQ7ACvEGYAOI/6r77fdL8/Ps4uXy3DTVBc0ex8HAF7rct2qzkbDfqm+iIKHzrSbDdNZD4AHfh9t93aDi+eEj313bntyv4TbmQuXT4iPhcNzD1QfMUMYEyKjQ1tjY3ZXhyOTh5wnqMOso7HTuLPIv9Wz5vgBHCV4RKBbNFRoUNxS9Fd0ZCx6UIg4njCpbLbQtsSxHK3QofyX+IUgfWR4wH1Eh3yBdHwIcWBmmGCgXdhVxFEoUFRjaGxQe9h9lIKci7SKhIN4e9h2+H7AhySBTH5wdER2cHJ4aOhcRFNsRzxCqD9oNLw0fDcQNjQ0sDFkLaAsfDCgMbgyDDIwNyA4OD+QPrw8BEHQPKQ7qC7AI5wVKA5MAbv13+Tb0uu+Y6i/lR9+02KbS0MwtyUvFKsJGvTG2UrIJuMXBicv+0dfRKdOw1grZ/9di183WuNsx4Gzh9uCL327gMN7V2AzT98840snWRdl/28LeKeN75gbo5ueM6cDsBPBr8hH08fgo/+4EvQhYCZkKrQ17EeYUWRfEGnMfVyR6J7cooSlRK6UseCxNKv8n8SeyKO0ovCdnJQYkAyNlIUYfhxyEHNwcBB1jHGQbkRwTHjQf9R1oHMcbaBwrHWcdqx1aHV0d2hxYG7Aafxl4GIQX1xXyFPETERRoFLMTIhM2EjcRLRHEEGAQQBAmEGkQIBCWD08P7Q7uDkMOqgz9CuYIZwZoBOMBQP/x/Kj5M/Zu8qvum+po5tjh7dw12CvVg9FQzkLKkMaVxr7JEM5zz3bQKNB/0FHR0NAr0HLS0NX11+HXEdcs19XX3NcU1b/ShdJy1fnXO9qL3EHfK+Mv5XblFObn57PqUe3D7l/wOvMD93/6oPy7/kABzQNpBnYIFgsxD2IULhmkHDIf2CENJZ0nYCkIKqIq7CvvLMgtoi2ILW4tOy3yK+QpzyeqJkom9iTfIx4iWiFTIUwgTh8dHqod6x2THZQdGB0aHdkdnB3THJ8bERrXGMYXJhYjFXkUYRQQFQ0V8hTHFLgUOhXPFGwUJhTlExcUoBPnElUSyREXEbUP6Q32C7UJdge2BJsBgP6J+w34WvSV8FzsM+gy5Mbf/dql1iLSBc6Qyq3GZMRBxQ7H2ckUyyPMIcy7y6rMkMsqzS3P5NDF0sHSGtOq07PUUNXw1OjUo9WV1yva09yn3/Xi5OWH53PogOl7693tRfDQ8Ufzy/WR+J/7ZP4AAagDIgaOCKcKoA2KEVMWuho1Hmgh+iMcJ7Eplys+LUIubC9AMOswqzFYMqAyeTKxMUYwAS+gLaIsqSv6KaMoGCfTJdQkQCMGIrwgSx8QHlgc6BqmGr8ZMhlBGGkWexVDFFMTiBKeEVEROBEwETkRIRGGEVISphKeEmMSAxIcEtgRDhFPEF0Pvw65DTcM2goiCeIGTwSyAAL9jfnI9RTySe4y6tfljeHd3EDYPNPZzqrK3caUxE/C1MIYxqDHAslfybLIL8kbyUfJjMpazeTPjNGF0k3To9Qq1irXwtfy2FTaMtyk3kfhd+Rt527qwOyM7V7vOPEV84D1svY3+Hr6Tfy0/uIAmwJ5BPEFHgihCvAMoRDnFGYZuB1cIJcjLid4Kp4tNC/sMLMyNTS0NV82ITfeN7Q3oDbeNA0zpTFYMM4uSi1gK+4pwygIJ8IlGyTDIoohWh+eHRsc4hosGq8YVBejFcwTfxIoER0QaQ/bDqsOug6rDj4P1w+vEIARvRESElUSLhJJEvYRbRHwEPQPMA9JDsEMPwsoCcIGtAP7/xf82/fg87zvDetc5vnhwtyE2CbTBs55yXvFLsLkv5m/1MDUwuXDycSXxHbFh8ZPx1HJJcwBzjLRzdG40lfUG9XV1xrYt9lD28DcUN+54WnkWOeB6ofsbe7n717xGvTa9Qj4xPnK+sT8HP4AAGcBfwIpBN4FCAh5CncN8RCOFcMZpB0rISckRSirK+guRjE+M4k1/jaTOE05CjqMOhw6MzmHNxc2ajQVMwsxLi8ALRUrxCl5J18m/SMXIh4gcB25G14ZxBe7FgYVixMcEjEQ9Q7FDYcMNQx7C1EL5wufDAIOzA6hD3cQ6BAtET4RDRFfEYURFxFJEPsOhQ3vC5AJFgfrA1MA5fyt+CL0iO+e6jXlq+BI233WV9H8zKDIgcTPwG++z70Vvgu/qr7av6m/UcCpwRDDgcXPyBfLl813z+jQ4NLx097VLNez2Hbaldz13gviw+SH5zvqWux17m/wNfJe9Ff2FvjB+Rf7vfz6/U3/qADLAdECHgTTBe8H4AoSDvkRAxZxGQ4dZyA2JAQoEysbLqswJjN2NT83vzjIOY46uTpDOtg4rjdENu00RDPWMK0uHSw8Kr8nLiXZIkEgDx4xGzgY9hWUE5ERaA+/DKMKeQidBk8FAQReA1UDTAO6A/0DsQQsBmwHwAizCWkKbAsiDIoM6AztDNwMbwwoC+oJZQhcBmcErQG9/v37sviH9RHyZe7P6p3msOKG3uTZ3NWo0UzN4MnUxbHCv8FfwFLATsCGwFrBXcKhw1PFHcjwypjN189s0gjUPdYo2K3ZttvN3Dbe89+b4bHjeuW659zpTutv7TPvSvGp88f18Pcw+tT7pP2+/2sBgAPIBFQGBghOCWELXw1WEJ0TdhaXGVEcbx+/IhQmTSlmLEwvkzHOM9E1oDfpONM5ETqoOYE4TzdkNlk15jOVMUUvrywQKn0nDyXPIoUgBB4QGwwYYRUqE3sRhg8/DQgLKQnyB9IG1AU8BRYF5QSfBFEEaAQQBQgGrAapBjUG3AWbBRgFDAS8AgcB4f4p/Kn4sfRS8NzrKeeF4pHd9tiI1P3PVMuJxs7BvL56vC27RLpFuVa5yLhOuR66ELy8vrnBucRhx2zKXM1k0I7Tydap2dncN98w4jbl/OeZ65Du0PG09NL2ifkV/IH+LwEzAxwFxQaYB5gIdQnRCVAKPQoFCmcKTwoUCzkMkg3lD5sRxBNnFhEZihyaH4UivSVrKCEriC1wL14x6DL4M5Q0AjQ8Mz8y8jCUL4QtYCs8Kd4mSCR7IZIeJxy9GfcWFRQuEYoOPgzGCfcGPwTeAfH/6/0W/L36+fmQ+Qj5sfiK+KH4Wvlk+lj7Ofws/XT+ef8kAKMALwGyAbcBwwHAAXkBFQGSAL7/jv4t/Rz8Dfv2+cv4evcH9nb02fIX8Zfvxu017FbqtegP51jl5+N34vXgsd9N3ondgd0Z3X/d9dx43aLdEt6v3kPfo+Dc4evinuOq5FjlW+ZE54fovenP6tvrMe1g7gbwlfFR80X1yPa9+M/6wvzy/vsAMgNPBZYGKghuCRIL1AxODooP0BAaEkkT5xRjFlwYfxpQHEIe9B/fIWYkeyaNKHoqmCsvLWIuTy8jMBYwHTCzL9Auty1yLEsr7CkhKL8lXyMEIQwfQx0hGzsZFRcwFSwTKhFoD9kNLQxtCi0I6wXIAzgB+P5t/OH5afdc9DvxJ+7Z6vLnveSi4SbeHtsu2GvVC9L1zWbKe8jrx4zGe8QBwrnAvcCqwMvAC8JUw/nEVMaWxhPHgcjJyq/ObtGe0yLVQ9fh2ZzcfOCl5OTomOz875PyIPYp+Tv98QBYBCcH5AjKCscMRQ7pD24RKRJTE1oTABSjFHMVcBanF24YjhloGuEbfB5oINwiJiTlJb0nbSnxKpMsNy7FL6cweTC9MGEwWzCwLwcvai5jLBgqYif7JXYkuyLRH4wdyBtnGZcX7RPKEZQPpg1RCrUGAwRLAmABW/+1/Wv7cvof+fv38/Z39uv2d/fG9zb33Pb99gv4mPja+PL4AflR+c744vgD+T755/gL+CH4j/ff9zf3xvYu9nD17PTl8yvz1fG+8cvwpvDo7ivucO1r7EvsSevN6xrrq+o36STpL+mz6W7pIOkC6bHoGOl+6eXqqey17druE/C67x7yovKy9cb33PiB+qb6wPum/OH9gP95APEAFAKBAW0C5wJDBFoGCwgYCXIKTgsEDSsP6RA9E9kTFRXCFf8WyRhUGvsaShs3G9sa5BvaHP0eLSAjIKwgKiACIQ8iPiMuJdElQyapJfAkaSQ6JFEkBSQuI2shoB9RHSAbFRnTFqwUCxJEDzsM3gjrBRADbgAS/RL69fYp9A/xu+1A6tXmLuMy32rbVdgW1k/UDtMn0EfLIcTOwOnD9stPzkXNJMo0x5rKNs180NvTxtet21zdgttx2tTbguHi6Lvs9e0O60Xp9+pi7kPzwvau+BD66flX+gf8ov77Av8FtwgUCusJ2gq1DO4O3RIZFV8VahVRFBUXmRmKGzkdJx2+HQ8ekB4UIY0jIiamJ6wnOif9JuAnzSn5K5ssASxBKnkoVyeHJrsllSX/I8MhEh7CGvwYnRbVFKMSMBCEDY4J3QbXBPACKAE7/7X9ZfvT+PT2dPbX9c/0r/L68FTvt+5i7ojuhO5k7fXsI+sY60vrueyg7nHvgO9G7kbt+e217+jx1PPM89TzP/JV8nHynPMc9Yf2HPix+Nj4bvm0+ib9zQB3At8EtgVqB9YJMgz5DpYRUROxFS4XUBh4Ga4aMB0XH48gwSCzIH8hwCJGJG4lCiVgJdskNCW0JP8jHyQPI68iziCYHq0dpxr5GYEXJxTAEq8MBAu4BikCLgD/+PD3SPTW8FLugeNY3JvW8NhY4OHf597v1/3RS88tzfHSq9br3Gvgw9422hvU6daz3uDmNurk6KzmFOXO4wTod+1D88L2FfM883vx/vJa9+H50v9o/v77Efyw+3L+NgA6Aw0GBQVqA0cDeQX4CIwLIw4KDykOJg54Dy8UFxg0G7YcphzyHZUeISF/JA8nailYKeAoYiibJ2oo8Sg5KfYn8iTwIrEhAyAcH9kdzhzmGrQWUBTkEdgQHQ/jDDUMSgq+B08EHAMiA1ACzAC8/4r/pv+A/nr9D/0y/fr+DgB1AZcAh//OAFMCcwShBIIEvAVFBs8GZwcuCJcJjgn5CBMJDAlRCRMJnwi3CB0IWwd8BpoFtQXuBMcE9gP/Av4B2QAHAdQAxgAtABX/ov5z/rX++f/a//D//v72/V/+bf5L/1H/YP5K/mL9Af3N/Ob75/tE+9X6Nfp4+Kr3RfcJ91D35/UV9ST0G/SD8/Py1vL58ij0rfOQ893xg/DJ8ITxFPM99C30dPR68y3yo/LI89z2EPn/+Wz6bvmk+OX45fpJ/vUAewHkAPz/gP+aANgB4QP5Bm4HowfhBd4E5QZKBxQKHgv5C3cNMQzzC74LzQxFD6AQoxF6EQQRYRATED0ROBI7FDgUpBNWEh0RbxLmEhkUHBTDExYT4BC0EOYQIxL9Ec4PCQ9mDIAMfwvTCvEKJwjmB4AFEgPhAqn/oP9k/Wf6S/ny9NHzdPAD7z/sAOo55rvizd603HTbRtmq2OXUTtSTzsHNLs7s01rbb9xn26LXwtfB2/ThUuZt63Psvu1A7aPsR/DU8nP31fix+Gj40vYF95b4hfp0/cr9J/1W/Zf8m/4IALADcQV0BNQD4wODBvIILgvdDOcNmQxXC1wMdRBTFPgVPBZpFqgWahfPGrQejyL5I+wieyI/II4griN1JsonNiRvIHMeLxyQG0MbYBsxG0gXixMdDz4NhQ0tDlYOGwucB1MELQJ9AWEBKQK/AQb/wvsA+ST5uPk0+sb69PqI+jf4tfYu97b4SPrZ+in7cvos+Wz4sfjM+SL6vfkV+UD4pfeo9hz27fUD9Ur0GfNq8xnz//H68ITwuvGi8fDw8e8079HvAPCd8PXx7/ET8rXwjPDK8SnyhfMS9OP0z/W99HD0kvR09XH28fUk9qj1O/Zj9fD1zvUG9dP0VPMs9I/0SPXF9Xb18fOw8hzyCfNB9WX2ZvdP99r1+/Xs9SH4i/ol/I79w/2B/Uf+yv9MARcFGQUKB70GSQdSCjgKwgzjDVQOohAKEPAQrxK+EgcWWBYkFw0YLxfiGIYZNxquG/YalRtaG4UaMRsLG6ob6BsBG5caxhn4F0cY9RfWFz0XChSjEgAQ+Q6RDhMMyArIBs0D1ACA/CT7Rfcn9HHwRuqT5oXgVd0A2pvW69FWyyLFzr74ulC3ZbbhscusCKbgo0qlp6iyrVeyYLZTtle3iLvGxZHQv9n83fvhcuN45mLrEPID+dr8p/3o+8v5ovgs/AAAvgMdAnX/v/w+/J396/4zArYDFASTAyMCVgQrBiIJqA1dD2QRIRANEJ0SBhVIGKUaHB3DH3UgoSEBI/4kWSdVKMUpAyoUK94p0ij+KAwpFil4JU0jpyEbICYd7RhIFkAVDRI3Dk8K1AcqBzsEQAKD/8P9Wvz9+eT4tPjX+CH57PjA+LH44veK90L3v/dg+a/6jftu++v6uPpG+r36lvsw/NX8M/yh+8T5PvjS9p/1FvU59O7zXPNZ8iTxa/Dm7vjvXu7/7uPv6PAA9uj1aPeQ9sP1KPjW9+H60gAHBW0HDQY6BFIGLQZUCa8LVg5uEVAP2g4YDVMOJA0uDBIMHw3qDogMzgmoBpEDfQKuAIoAGQGP/rL9Tvrp+Jn38fXl9RH36PdR+Sz3jPbM9oj2Uvnv98D5r/lz+9/7+Psp/CL7Jv3w+yL+iv2w/Fv9XPro+yf7kvoY+0r4a/hb97n2VffL9fL2Kfdh9tz1sfNQ9Vb1RPYN9wv30vel9Uv29fcW+hH7XvqA/Mf8XP72/YcAPgMjAwcFEwUGCZgIgwdZCCMK9ApiDPAKEg5MDEwLTQviCRwNowlsDOYLQg6NDGQLjQvdCYwLswlEDE0L0ghgCjoJ8gxYDucPOhL1DBgJSgXcBmAJSgq6DvUO6A4oCbYCjANoARkEGwNZA6QDMP7b/c761/k0+pn1PvaK8a3s9Orj6FDvAvHe87bzqO5S6+TlUOux9PX/lgVwA7IC2f0g/FP9LgNDDMkQIw/1CMwA6Pzq+2/9sQETAvQAQfyB9w742fbt9yv5cPs//5b9RP6JALIC6gRWBO4FIgcjBw4KsA3DE8ITIBMZFBwVhBi1F9cbcR66H60hAR/rICAgfh+3IYEgfyCTHUYcLx1cGqQYWxb5FW8UbhC0DsYNYA7eDJsLmAucCQIIvQZ/Bz0JeQfNBn4GZgdBBmEDKQItAjADugGo/+f9zPv3+UX39/Xf9PLxrvCQ7uruZO2r63PpY+eS5B/iIt8I3yzeft9B3kHbt9kX18DaEdr33VLgzuSZ5cjkDeap65DwRvQV+BX5w/qq+hL9MgTDCEQKhgrdB+4J5wdWCdkLGw8QEUIQIA5EDl0O/g6kEqsU1RcLF9kWBhkmGkMcER1sHpEgwCCjIWwjFCW2JhcoNyh1KXgocCjHKRwpbCq+KNwmAiZ7Ig8igR+qHD0bYRejFF0RNQzhCocGbwPr/1T51/d48XDueus35WLjfN2u2EDU7ss4ybDBq7vptguwc60+pzSjBKSXoyOhfpsmoIeyEMjv2J7bZ96T3qjc0d3H5qjz6f8PBzQLUAu/A6P9ufil+yn+Uvwt+VH6H/1oAnID6QGcAH38b/wn/uoERQ3yFT8bsxxCGvYVshVxF3QeniZqK74tmy1rLe8v+i86LzUvti44L+ouCC9JMdIyZzGVLJAlUCAEHIwYthYiF/kW1BPuDtIKUAjfBawBIwFtAPsA1wDO/20CFwLzAEX/yfxd/SP9GvwD/vT+3gEOAeP9Qfr798/3yPdi97n1JPZn9C/0m/Nv8rTyAPJC8iH08vQF92T40Pm1+4L7m/u3/Oz+lwLjBbEHvAhxCH4IcgjCCfkJowzSDJcP4w9cEH0QZQ8JEs0ULBncGwgWEhrFJs4jxx0EER4Q2g0lD5UO1AxkDywKSwmnBRcDyQBj/Db+pAQ0ATgAzvtZABEFvwPnAsT+BAIO/U/9zv3zAK4DRwFBBRcDv/7E99n1x/gH+X31c/TW8jf1CPF78FXvxO2/7s3pLu5F67vteu0V70nzAvKl8lTyKvOJ9hn4jv0tAYEA8gHRAAID2wTRBCQGIAYvB+8H0QhLCtcLIAsFCXIJ7gaaCdsHpwo5D4QOVxC9C30NDw+6DWwQmg8KEnYR5BAXEx4VURUgFAUVFBVGFZ4T8xPEFQsVNBNTEIwPCA82DqYOWg2lDXII+AVkA88B+wFs/Y/8PPua+CD4u/N8817xquwY7VPnK+Zs4endad1v2GXVcdI1zZPKfMZ2wV3AE7rzuWe6jrZPt8K8z9Hj6XL1MfzC+qz5wPUx9Ff25ftcBGMIOw3+DMUJaAIt+0T33PSn64bk2eBG5n/wlPdb/a39Q/wC9q/xB++L80D57gCaCUcQ5xSLFj0aFRzjHGQYPhSIEl0TiReRHLki8SbjJIcfcBhXEkYOIwwkDhAQuhDtEIgRMxJQEaUOfw7/C84KrgcUCvENABAJFKcScRMsD58LDAtnCjMLcAqqCrwMigzRDAkM+Ao2CZMFuwGw/iX8LfyX/b7/YP/n/d/7vvlx+Fb22/eD+Dr63voA/nT/TQNBA8EHZwjIBUIFgQNOBqoGSAkCDd4PxA4fDRALCQ1MC7QMnwsLD74N5wxTDSIOgRI6DkcOJwpuCTEGAQN/BDAHeQhjCE8GBgcbBF4BAQEMAtgE6f9/AaH/BAOJAWIAZwJ+/yb+ffoE+tD6BvkY+FP7KPqI/Or2nvnZ9xr4uviy90H8z/YT+qP7SP/Y/dn6J/uw+WL1BvaN9/b8Zfxg/TYAr/7c/4L5bv6v/eMAkv+P/uYCOQB0A5ACwAfbCKsGigeOB4wI6Ai+COgMqQ74DkEQOQ/5EDUPCxHuEc4RNxE9DzYRaRA6EdESdBPhFLAS1xHAEV8P0g6qDkIPFhA5D9wPhA/YDFwLagkmCP0FYwIjAYH+4Pwy/Fr6M/nt9InxtO4E6/7nX+Pk4ODemdnx1cDQbc1PxmDAQrtjswOyLKvmq0mqZ6cypxOnlba+ySDePfED/HkDPQOe/wz+/PzT/eL99QH9AzUERACA+6b6z/dA8SfmC9142O7Wn9qm40zwAPs8AIcDygR/BPkBpQJCB3QNyRJSF+AdNCRmKe4rBC1gKgokBx1jF4QVHBW7FkQZlBp2GpIXxhPyD3UM5wnhB9IGzwZMCHcLWg/OE2sXlBjtF70UpxFoDv8LrQsjC2IMoQzeDHoM5wrcCFgGpwNUAHr8IvlC94n26vcJ+dr5YfmA+DH3ovW98w/zzPPP9T73+fjx+nn9qf/JAYADjAOEA+kBdgNcA7MEVQWwBhUJZQkRCS8IVQd4BxcGzAZxBo0GbgZCBkcLvwsHDjYMww2oEFkQmw//DncPVxIJEpoT0xVWFUsW+BOsFgUVghM6ER0QWxLAEHcPNw4HDh0QrA2ADYIMQwqrCh0IMgmsCL4IaAiuCJMLggtrCYwHQQckCeUH5gefCEgJJwrdCB0LrApCC94JcArEC38KCgrhB+wHSQl5CaAJkwk5Cz8LOAq3CE8IAAmbBZAFKASSBywIxQabCPkHIQkbBn8E1gbnBZkFuAPQBO4FogM4A2QCjgX8A+ICqgK5AUQCJv/z/zwBvwCwAJv+/wC6ABv/Kv4g/jUAWf8T/4X+cP5L/u39NP5H/p39cv3E+7P8F/wX/CH7ivmO+zT7WPvm+ZT6S/zY+7n7jvtu+9/6Qfll+uv7uf2m/YX9Df93/pH+Ov1k/iIAHQAFAE7/0P/7/3z/QQE7A04EZwOaAlADKwOcA7EDsgXxBvsGKgiXCAAKtgqWC4QN1w1zDo0Oag+kEHgRgBKnErES/hFlEe4Qxw97D/4OaA4hDsMMfQzdCtUJAQl2B1kGfQQQA7sBK/+A/NX5svYv9HDxne5P67vnOOSI4a/cZtny07vO48iKwW68rLZCs+iuQ627qTqnyahzsbPEotnl7sf+sgepC5wG6f/M+GzzwPDk76nxTfKd8rbwbvDs7wjtKeYz3bLWSNSs1ancZeeb8x7/RQjGEGsVKRddFusViRaJFmoWaxiFHHMhDiazKTcrkiinI50dWhimE6wPzQ0tDZINAg4xD1ERXhPqFLMVUBWQE8YQVQ6fDbQO+RD0EgMU4BPyEY4OUwovBhwCsf0w+nb3DPZX9EfzS/N29E72a/f+90L3hfU/9JHzVPT69FL1kPUn9qP3K/hg+Zf4qfld+Wn6ifrH+uT63fpK/IP+BwCjAA0DewJYBRsEGwUWBFsD2AT2BPYF2wbyB1wJjQsIDG0NLg2wDckNtQ0cDZ4M7Qo5DFgNNA6+DikNyQ3sDMsKXwmXB/EGfAVyBMwEJwRPBAQExgSfBJgEIAOOAa0AlP+z/mr9Mvyp/LP7n/to+6z65Po++f/5aPkO+oX4Wvg4+Aj5Svm9+Uf6PfqZ+jz6N/vn+Sv88/qQ/Z78af3l/FH8Cv6k/vn/yAAgA+UBUATLAL0B9gHkAbsBSAFRAaoCtAOBA8gFdARBBuoDlgTkBecEzgQnA6kE6wTQBBsEOgQ7BWgEbQTxAwkEMQMtAUIBtwAX/xX+nvzs/13/7v4j/tP8T/2V+4/8I/y6/Er7Ivsi+7H6Tvqw+Ub63fpD+r35DfeA9ej1efUc9jf1ePYg9/H2V/bi9VL1uPSB9J70dvXl9f/0bvU59kv3QPjL9vD3Sfjc93X3OPbh9tj3Mfgp+u775/x0/an9j/7z/v/94PzN/Nb8Av7Y/qL/TwEjAsEC6AI/AhgC8AFeAvsDcwXxBjkIRQlYClcLXQu+CqEJjQi/B9AGHQa9Bc8FBAagBp4GzgZKBjsFEQQpAmAA1f46/bb8nvxi/NX8yfut+pf5rvej9aPyIe987Dfph+Yk5VbkSeTC5Knk+eOY4vveQNsF1urRt8yrx9zEssFJw9nDCMZcyd/Ky80Cz5zTgdqb4TTp7u2G8mTzFfNR8lDum+wF6DblQuTZ4mHkEOSM5evo0Oph7LrrDOzx7LztvPAX9Z363v6BAl4GOgpSDEQM2wsLDC8L0AjOBqgGpQe3CD8KiAyhDqwOEg42DtkOYw4FDbwMWg1KDc4Meg2SD1YREhLyEaoRrxC8DXMK4gfaBbYDLAJJAcgA2v9j/ycALQEHAmIBsgCu/2/+Qv0V/Hr7T/sB/Pf8g/2u/V/9wPyG/BX89/qW+Kv2Z/Uu9T/2APfV+Hj5tPr3+9D8b/3X+z/75Pu1/kIB/AGwBJMH/wnRC54MwQ0cDGkKEAh/BaEDGwIkA/0ESghjC/4MBg4qDyoQHhDeDuEO2A0FDRIMaAysDPwKZwv+CpkL+gk8CH8GVQTmASD/Sf2K+8X6gfra+jn7ZPta+j366PgX+A/2+vO+8f/vsO9670HwVPDI8Jvw9u+67rDt3+sX6gLpZejJ5jjm0+Uk5vTmRujJ6vrrN+247ELt8uyk7JDsmezD7OPsFO6h7/zx5vMf9in3cvf69uv16PPq81v0y/U995z4y/qU+9z8if7hANoBUAHE/xv/bP62/tH/hgKxBSUIPwp+C4kMXwyqDJsM7gxdDLkKGwpTCkYLbgzmDHgNEw7jDWkNmQ04DhkPURBMEfUS3RMvFJ4UYBWjFU8V5BMwErIQGw+vDV4MZAuhCl4JrAcEB7cFJQWkBHgELATFAgYBaf8q/WL7g/lZ98r1mvMG8lLwCu5R7FDrAulR54vkUeLg4Oze/91z3VndTd313JPcmdzv20vbzNsX3T7fReKu5EzoAevP7PnstOsH6vvmceTD4YrgWeBw4QXkO+cz6wnuIfB88cnxY/J+8r/zffXT98/6Vv3d/zABQALKAiwDAwPEAaIAk/8s/43/JgEDBF0HAwtjDmgRqRO0FP0UuRRbFCQUkxS3FTsXyBi/GXcaURqqGWYYcBYxFI8RKg+uDCQLCwrkCa4KOAzRDmEROBQ4Fi4YFBkHGfAXMRZbFJgRag/3DUENkwz+C+sKygnACIEHtgbcBiMHLQc5B9AG4gUVBZoEYARhBU8GqgaZBv4FsgQFBEsDWQJbAWkADQAy/5b+SP5R/qb9S/22/Fz81fuw+nv5aPjZ92D36PaB9mT2YfYE96v26fZC93v3o/dI92/3aPYM9H/yU/I/88XzjvSQ9br2UfdN9rb1tfU19iH2rfbP92H4CPgq+X/7yf7EAEMB7QGrAR8BsP5H/fX8Kf0i/Xr9If8tAGwBNwOnBeMHjQhCCK8HCAh8CHsI4gh6CYcKPgsqDCUMtQtTCpkIVAdVBkUG0QXjBsQHewm2CqML8gxTDQwOJg14DO8K6Qn2CfIJxgoHCz8LywsZDJ0MdQwNDFgKTwn+B4sGlgadBZkGdAddCOwIZgmTCQYKsQq6CnUKwwipBgcFQgQWBC0E2AMCBNYD7wNrA1ED5AJ+AmgCTwJtAlkCkAIaAiwCqAE/AfkARAH1AVEClQFFAKf+Vf1z/UH+LP9L/6n+h/3k/HT8gfx+/Kj82/yG/Sz+Tf6t/j7/p//u/6f/b/5M/dn7r/qc+gX7ePtJ/IL8KP1L/Vf9gv24/R3+zv57/23/lP9s/8H/2f+EAKoAKQEtARYBxQBBAIEA0QBOAoQDgwThBL4EYwS4AxwDJAR3BCMFhAXVBfQFxQYeCGUIUAmeCI4IJwiICCoJBgphCrcKqAolCScIjwbQBZYFWgUBBWsFqQWlBQwGlgZOB2IIcwmdCaUJMQmcB0YGEwZQBSgFIwULBdwEKASvAzICAwJ6AQgBqgD//8T/Kf+4/r3+gv/E/9j/xv/V/+f/2/+O//b/OwBjAM//qv4s/VL7SPrl+ST72fzY/lQAqAHtAoIDQQPWAUkAIf5D/ET7mfoG+1j8gP3F/dn9d/5O//b/YACRALMArAD7APsBNgPcA8oD1gI9AQoAw/6s/Vf90P0k/0IBjwP1BWwH1AelBxQHsgZEBukFhgXrBJADvgLZArACYgNbA6MCeAGy/z/+jf0E/5IAjwJmA0QEdgURBmYGJAboBXcEkQO0AvAC4APDBEEFxgTOA6AB4v5x/JP7bPyg/Ur+Yf+zAFICXgPxA8QDWgJyAPj9dfyx+xz8cv3j/5YC7wRzBoEGdAV4A/sAbv7E+2f53ff99rj3lfh/+rb8nv7r/20AHQC3/nj81fkN+FH30/eJ+Gf5/vr8/OH+nwAwAcUAX/+3/ZP8Uvy9/OD8Yv1P/qP/zADyAFUAU/+t/k39a/tS+lf5x/jP+LP59vqN/Cn+jP+YACoB2QFdAsYC1gJ8AkMCwgHLAPj///4H/qL9Uv0a/bX8HfyY+8n7Cf1h/1IBaAKhAzUEnQS0BCME6gJ9AW//Yf3M+2f7xPs+/Mz81Pxn/Sf+1v5h/zcAhwBdACIAVQC7/0T/Uv4f/XT8evv5+ib6Cvo8+V/59vid+NT4IflK+qv6hPtP/I/9qf4s/xb/uf75/mP/mf9l/5H+9f3J/Rn+jP7A/lT+fv3u/Kj8h/w6/G/8y/x2/RD+nf49/7b/AAC2/9z+/f3T/f/9Ov6d/mz/rwDQAWcC3AJzAkkB2f8X/n78K/xR/In8Ef2b/a/+af+dAEkBugFsAUMAr//o/vT+df+g/3P/Nf8U/2X+jv2Y/EP8ivy6/Oz9//+FAnMEuwVzBfADVAFD/f34+PVv9KrzIvQJ9hn52vz8/zwCbgMOAwsCu//y/D/6VviN9/T3QPnH+tb7MPxu/Hb8HfxR+8X6R/ol+s/5Z/kv+cb5NPs2/Kn8+vz+/PT8WP2s/Y7+3v4L/+r+sP4D/6n+M/5e/bP8V/x4/AT9wv08/qn+0P5w/u/+gv9IAGkARP9F/uD8vfvF++37efz0/Pz8vfzM/Mr9Kf9cAKAAhQAuAAMANAA0AIj/N/7C/CX74vlu+d75ifo++9f7N/xB/Db8V/wl/Lv7wvp5+SX4CfcN92n4R/o1/P79c/+NAMUADgA0/sj79vgb9t3z9fK48731tfiD+xz+rQARAiACkgG///L8zvnt9kf1fvWY9/P5Lfyd/rAAqgEsAbT/2/1T+7f4Sfcg9//3UPkh+8r97ADPAmED3wI8AST/u/yM+vj4//jB+eb69vzd/sf/tv8e/6P9i/st+eX28fUb9nH3lvnV+zH+TABoAV0BGwAG/jT7hfi19uX1XfZv9835C/w//tP/ZgCFAAMALf+q/fT7HPrf+Dr4dvhu+R37qvyV/Vn+Z/67/ZL8lftW+3X7jPvR+3/89P3O/2gBQwIyAkUBuP8F/j380Pqj+SX5NPmW+YD6ZvuK/LX94f46/4n+WP06/C38Bf33/SD+P/7O/sP/FgHRAbcBhwDS/hn9sPur+lr5QPip9/z30fi1+cL6cPs3/HH8ePvI+X34Z/hw+Kf4Ofkc+pT7Nv3O/uL/PABs/9P9oPyu+yv7vPoD+uD5Avrh+fv54/pX/CH9vPzp+xr7uvrK+hP7PPv1+sn60fpn+8f8O/55/2IApQDgAP4AEwHQABgAm/9j/u78JfzK+4b8lv0M/pz+ef4s/nn+ZP46/pn9H/ys+tz55fms+pX7N/zQ/EX9wf1n/sT+WP4c/Y37K/qP+cL5lvrt+4H9+f4ZAGMA0//C/vj88/rb+Dr3YvYP9s/2dvhs+pn8lv4DACUBZQGxACn/QP1o+/f5Y/lz+V/6l/s2/ez+ZgC2AScCegH+/0L+jvxQ+8n63fqU+2L8Sf1m/l3/BwAoAA8APP9h/kz90Pul+xP8rfw+/bL9e/5F/r/9qP1H/dr8Hvyn+2D7g/so/A79EP7R/nT/d/8q/xn+Yfxv+vP4Q/g1+Jf4L/mM+jL8+v10/9QAiAEAAW//Af3e+rD5fPl4+g38/P3C//wA0AEPAjoCBwFy/s/7z/mG+LD4y/l5+5f9lf9fAaUCywM8BG8DYgE7/7X9vPw1/GH8Tf0A/wQB5wJOBNcEgAQ+A8MBCABx/gr90PsP++v6uPun/Jz9fP6//hP/8v5d/ur9sf0M/lX+w/5w//D/kQA/AasB7gGTAaUArv+d/qf94PyU/IL8wPxs/VP+K//U/20AiwBNANr/B/9k/kP+kf6f/4EAbAFCAlQDrASTBTYGuAWEBCwDMQKbASYBiwDH/w3/w/5a/0QA/QBXARwB0wC6AJgAqwDkABQBZAF9ATABbAElAu4CYAMhA8MCPwKFAU4B/wArARwBfQBDANH/l/+W/53/Qf+6/hv+2P2t/Qn+Vv4m/l3+VP7T/jn/ef+O/2v/Vv9I/5X/q/+X/yUANwFfAmkDRwT1BC4F4ARJBJEDdgJ/AY0A0P+S/5P/2f9QABcBGAKTAlgC/QGsAacBgwEHAcUA5gBsAVICUgPIA8cDbAMCA50C7QFLAZIAJQCx/8D/pADLAd0CngMMBM8DLQNmAnEBYAA1/5L9NPzA+3/8K/6b/2sA7AArAZwB8wFMAhYC8gD+/2v/zf++AEcCigNzBPoEMgRyA/ABGgCL/s78rfvk+kf7//zt/h8BIAN2BC4F2wRCBO8CfQF2AJH/ZP/Z/zkA1gAVAi0DOQQ7BI0DrAJ/AY8Awf8d/wz/J/+3/7YAwgHnApoDtwNPA3kCfgFQAGb/3P5k/pX+2P53/zMAOAFvAlwDcAPnAgoCBwFzANz/sf+G/3T/nf+EAGwBjwJTAzAD3ALTAfwAGAAy/5v+Uv6m/gf/ff9MAPoAxwFEAsICRANiA0oDVwM6AwMDCQOqAncChwKCAhMClAEYAUQBAALVAnwDXAM8AzUDUQNEA90CkgJtAnMCxgIdA0kDPgMEA1gDqAPZA9cDQAOpAkwC4QEyASUBnQGRAs8D4wSmBQMGFwa7BeQE1QPiAhACewEqAT0BnQFtAl4DOgTBBKwEEwQwA18CtQF4AZABzAF9AqMDmwQ8BaAFsAWHBRwFdwShA60C4gGWAeMB3AIhBEcFKga/Bu8GjgbLBZ8EPwPTAZ8A3P/n/4QAZQGnAr0DlwQHBfQEhQTXA0YD5AKIAj4CCwIBAmACJQP2A6UEKgWBBYkFMAWUBMMD7QJ3ApIC0QLhArQC8AKUAzkEIQWDBU4FGQX8BNcEwgSbBCcEvwObA9EDEgQrBKMEJwWEBaQFQwUPBdkE6QQgBesEfARCBHgE2gQtBW8FjQVaBRYFOgVIBeEEUgS+A4oDlAPQA68DkwNxA0cDDwN7AgYCkAFkAUsBlQETApMCWgNHBOME2wRmBH8D0wJuAhwCLAIeAnQCEQPNA6AELQWzBZEFMgW7BEEEgwP2ArICegLWAksD1wNMBNYEUwVKBf4EiATcAzcDyALNAn4DqwT4BVUHTggICXgJTQn+CDYIdAeJBmgF8gS0BOwEgQUmBmYGKgYqBuwFqAVbBeEEhQTtA6wD2gMbBG4EkARcBDEE6gPFAw8EyAN5A0QDBwMCAwwDWwOmA6gDjgOZA7ED3gPUA6IDzgMpBK0ELwVUBY4FwgX8BRMG4gWWBQ4FdQQKBNsDmQNHAyMDYwOdAw4EnQQjBbkFJQZpBjkGygVgBegEuQSNBE8EBAS+AxgEfgQkBb4F4wXPBZsFQwW/BBYEawPDAhcCuAFtAUIBOgFBAVcBWQE/AW8BZAFnAVIBkgDb/w7/pP7G/v7+aP/Z/y8AvABbAeMBHQITAvkB1wHBAeABPgKBAvgCXgOmA8oDsgOeA18DKgO+AiACeAEmATUBagGHAd4BgwJBAwoERwRIBOkDdQMmA/sC0gJiAvIB9gFRAtACXwPSA24EmASzBNoEogQ7BLMDRgPVAhsCigEDAXwAFgCv/4r/jP/l/zAAMABIAIUAgAC2AP4AhAEzAlYCnwLbAkEDbAN+A7EDfgP1AjACdgGFAH3/z/50/jb+CP5x/mn/LgAVAdIBiAJfA9sDRAT2A34DNAPnAsgCxQK2AocCiALFAkYDkwN3AzoDwQIlApsBDAGuADEA8f/J//L/kQABAVgBlwHQAdkBxQGgAT8BlgD5/47/b/98/9P/NQC0AM8AyQCpADYA6f+D/yn/ff7E/U39Tv1t/fn9mv7i/gf/r/5o/uj9UP22/Bj8JPx3/CT9Cv6y/mr/IgDGAH4BoAEYAYYApv8V/5b+EP7P/br9Nf6R/pz+ov6E/n7+y/46/1X/J/8A/wf/Of9n/5H/m/+v/9z/DAD4/4z/6v6R/ln+df7f/sX+rP67/vb+EP9J/3X/i//v/2EAhABOAOH/Rf/I/kX+5f2G/Un9S/2g/TT+pv4M/0T/EP+d/hf+Xf2p/Cf84/sX/Jb8Wv1p/mz/EQA5AAAAj//P/rn9iPyH+yv7bPsm/Cf9P/49/0EAGwFzASkBOQAc/yf+tP1l/RL9Ov2r/TH+6v5X/1j/6/5v/t39Wf1R/Uj9Vf2P/RP+6f7a/7UARgF4AW4BOgHYADYAWv9i/pT9SP1W/ar9Df5Y/rn+B/9B/3j/I/+l/kz+I/4D/sH9ef0l/Qv9aP0k/sj+L/9h/6r/xf+w/0r/lf7w/cT9I/6X/sn+5v5W/9P/lwAaAScBxwAVAIz/Lv/j/sv+mP6K/u/+bP/q/z4AegBgABoAgf+w/hD+jf1t/br97f0M/gD+H/6F/uD+Af+C/gD+oP15/Yf9eP1z/Wz9cv2w/Q/+af6I/qL+eP46/g3++/0h/iD+JP78/aX9R/0i/WT96v1r/sf++P43/4H/9/95AL0ArwAxAMf/cv9w/5X/tf/A/7H/vP8EAHoA7QAXAcYAUQC+/4r/m/++/9P/6/8dAFcAqgC/AH0AGACn/0D/+/7I/qD+k/6s/sz+7f7C/on+Xf5l/l7+GP7U/Zr9vP0F/nr+xP7f/tf+y/7U/rf+Yv7+/cv9wv3I/d/9KP5s/q3+vf6l/o3+af5K/lv+bP5U/nz+w/5E/+D/ZgDJAAEBBAGoAD8A0/+P/1n/Nf8w/zb/kf8pAOUAjAHqAc4BeQFDASIB+wCpAHUAmAD0AG8B2gExAloCSwI1AhICtgE2Aa4AHADT/8T/2v8YAHkABwF+AaMBfgErAcwAdAD2/0v/q/5O/kz+of4S/3f/wv8CAFsAkgCGAFQAJwDQ/4D/Z/9+/8X/CQBqALQAywCtAFYACADx/9n/g/8d/+/+Ev+H/wYAhgDtAB4BNwEnARAB6QCRAEIACwABACYAdAACAX8BygHaAecB8QEHAg8CIwIkAs4BkAGCAaUBswG5AawBsAG4AeABFwIMAscBYgEDAa4AdwB4AL4ACQFKAWABRwErAQoB0wCPAEwANAA+AHQA2gBHAZMB0QEjAlICNQLIAQ8BSQCX/wr/0v67/hf/oP9GAPsAjwH8AfMBwwGDARQBZQDU/1r/N/9w/8z/RACxADYBtwEeAiQCDwLsAZkBTAFDAY8B9AFdAsECIQNiA10DCwOhAhICfwHXAGMAHQDQ/8r/+f9mANUAVQHNASkCfgKxAs8C7gLSAp8ClgKDAnECXAIbAuEBsQFcATYB5gCAACgA3//J/8D/+P9RAKoA3gAvAW4BmAHhARECOwJXAlwCcQKQArACuAJ5AkMC7QGgAX0BUAFTAXQBhgGYAa0B0gHmAdQBsAGIAX4BXQFMAUEBQgFkAYoBxAH1AQsCCAIeAlQCUAJBAjQCEwIDAgsCKQIsAgQC5gHEAaMBjAFKAfMAqQBnADQAFAD///r/3//Z/+3/AwAvADsAUgBRACgA3/+A/2D/VP9t/2//V/9d/2v/of/6/zcAQgA9ACUAIQATAPj/4f/g/9f/4P8GACEAQABYAGQAWwATAKb/av9R/2T/bv+a/9T/KACmACsBsgHPAbkBpQGKAWQBOgESARIBBAEgAYkBygEdAl0CbwJsAv0BkgE+AdEAeQAdANT/r/+4/+n/GgB5AOcAFgFHAWcBdAFnAV4BNgEpAUUBEAHsAL8AgwBWABcAAADm/7z/f/8U/+z+u/6F/pP+rP7w/l3/5P+PACEBkAHqASECMwIJAp8BBgFbAMb/YP8f/zL/df/P/04ArgD/ACsBEAEEAeAAqwBhAB0AIABEAIEAvAD6AE4BnAHEAbwBggEbAZ8AKwDC/5n/jf+p/+L/FABKAHoAjgCBAEEA4/9w//D+kf4z/g7+8/37/Tv+c/6x/u3+Ff8s/yr/Gf8D/83+o/6W/qD+vv7q/iT/P/8t/zL/Of8Y/87+e/5A/ib+G/4b/iz+Qv5r/pD+w/7u/hP/GP8V/xP/6/7I/rP+v/7U/vj+H/8r/0j/VP9t/2P/RP8u/8v+jP5b/jL+JP4m/kn+bP6b/sT+3P7i/sX+gP4y/uL9rv2I/X79pv3P/QD+Tv6u/gT/LP87/yf/9v7A/nv+Qv4j/gj+8f30/fX9DP4d/g/+AP7i/cn9qP2C/YD9kP2w/cv97/0W/jP+VP5e/mH+P/7+/cH9lf1+/XP9eP2O/bH9yP3i/fD97/3a/an9af0r/QP95/zg/OL89vwS/TD9Sf1T/VL9TP0z/QP94PzB/Lj8uPy//Ob8Av0S/Tf9Sv1P/Uv9Nf0F/bv8ivxw/Gj8ZPx0/JX8vfwA/Rz9L/1C/Uf9Qf0p/Qf94fzR/NX85PwF/S79Yv2V/a/91P3M/br9n/1o/Un9Kf0a/Rb9Jv1E/W79lf2y/cf9wv22/Z/9gv1P/Sb9Gv0X/Sz9L/07/Wb9iv2Z/Zr9g/1q/Uj9IP0S/f784/zj/Aj9MP1J/WH9ff2H/ZH9jv14/Vn9M/0J/dj8wfyq/KD8o/yl/LT8vfy//Ln8svyu/Mf82fzX/Oj8AP0m/Uj9Zf1v/Xv9b/1S/Tz9Fv0J/Qz9Df0h/UP9Yv2F/av9wP2+/cz9qv2C/Xv9bf1z/V79ZP2V/bn91f3m/e/96P3Y/cn9qP18/WX9Wv1W/Wj9dv1//ZD9pP24/bn9t/2m/Zb9k/11/Wr9Zf1g/Wf9eP2D/ZP9of2U/Y/9a/1c/Vr9Nv0w/SL9GP0c/Tr9X/12/Yv9nv2k/ZT9h/1p/Un9Iv0J/QP9Av0T/Sv9Sv1u/aH9zv3j/fr9Dv4R/gr+Af7x/fD98/3z/fz9Dv4n/j3+SP5G/j/+RP5L/jv+Pv5D/kD+R/5c/nD+fP6J/qT+sv6q/p/+nf6l/pX+hP6U/pD+jP6c/o7+i/6X/pL+cP5a/mL+Xf5C/jn+Qv5Z/kr+UP5k/mn+cf59/ov+gf6L/nz+b/5o/k3+SP5E/i/+SP5S/kn+Vv5V/lf+Uv5Q/kf+RP5J/kf+U/5r/p/+vP7M/ur+/v4T/w7/B//2/uv+4/7V/uD+4f70/hP/Fv8//1X/Zf9+/5H/vv/B/83/4//n/wcAIgAmAEAATwA/AD0ASABEADwAQgBLAFsAdgCNAKgA0QDvAAUBEgEvATkBKQFEAUwBTwE5ATABQAE5ATUBOgFHATkBQgFJAVcBVQFdAWABXgF1AWYBYwFWAT4BMwEdAQgBEgEDAesA8AD2AA0B9wD2APwA9AAPAfoA7wDzAPgACwEPAQkBJQE9ASgBNgFPAUcBTAFDAS4BQwE3AS4BRwFaAWUBbQGXAaABqgHMAcoBwwHPAdcB2gHfAegB9QHwAQACHAIxAjUCLwI/AlkCYgJtAmkChgKLAm8CjQKWArECswKtAroCrgK0ArwCyQK+ArgC1ALaAuUC8gLXAswC4QLRAtgC3wLeAt0CygLQAsoCvwKkApQCmgKcAqEClQKUAqICpAKvArsCwgLHAsUCzgLUAswCwgLBAsMCtgK7ArkCuwKzArACrgK1AswCyALXAuEC2gLcAu8C6QLxAgEDBwMLAwkDEAMSAx8DGwMPAxwDHAMlA0ADRgM5A0kDZQNjA3ADeQOFA4MDgwN2A38DiwOGA4YDgQOMA4gDjgOPA4IDjAOcA5wDlgONA6gDsgOvA7MDvgPGA8oD2gO8A8EDzgO5A7QDowOfA5MDmQOkA5gDjAOeA7wDsQOwA64DwwOzA6YDvQOzA7YDqQOoA7IDuwO1A6ADrQO1A54DlwOeA48DmwOfA6UDpQOlA7oDsgO/A9EDzAPTA+cD+QMCBPwDDAQWBB4ENwQ/BDsEIwQQBCMEHgQQBBUEKAQzBEEEWgReBG0EXwRmBGMEYgRfBFcEXgRTBE4ESwRTBFQEWwRdBFcESQRFBEAEKAQhBCMEHgQeBBYEGwQjBC0ESAROBEgEOwQwBCIEDAQABP0DDAQXBBMEIQQ5BE8ESAQ6BCoEJAQkBBUECgQQBCAEMwRBBFcEYwRhBG0EXQRwBFkEMAQiBBYEFAQnBD4EUARZBEwEZARsBHAEUwRcBEYELgQ4BCwEIQQaBCwEKgREBEMEVARmBGUEXgRgBGAETgRIBDcELQQxBDcEKAQxBEAEOAQzBDEEOwQ/BDQEMwQ7BDgEPARNBEcENgQvBDEEHwQEBAUEBQQNBAoE6wPtAwMEAwT+AwIE8wPvA+ED0wPUA9MDygPIA8kDuwOUAw==\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Generates 1 sample of the target word for manual verification.\n",
        "\n",
        "target_word = 'sanja,'  # Phonetic spellings may produce better samples\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "if not os.path.exists(\"./piper-sample-generator\"):\n",
        "    if platform.system() == \"Darwin\":\n",
        "        !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator\n",
        "    else:\n",
        "        !git clone https://github.com/rhasspy/piper-sample-generator\n",
        "\n",
        "    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt 'https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt'\n",
        "\n",
        "    # Install system dependencies\n",
        "    !pip install torch torchaudio piper-phonemize-cross==1.2.1 piper-TTS\n",
        "    !pip install -U datasets huggingface_hub fsspec torchcodec\n",
        "\n",
        "    if \"piper-sample-generator/\" not in sys.path:\n",
        "        sys.path.append(\"piper-sample-generator/\")\n",
        "\n",
        "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
        "--max-samples 1 \\\n",
        "--batch-size 1 \\\n",
        "--output-dir generated_samples \\\n",
        "--model /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
        "\n",
        "Audio(\"generated_samples/0.wav\", autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFrQlw9q5R6v"
      },
      "source": [
        "### üîä Step 2.1: Generate Multiple Wake Word Samples\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Generates a larger set of wake word samples (1000 by default) for training.</p>\n",
        "    <p><b>Key parameters to modify:</b></p>\n",
        "    <ul>\n",
        "        <li><code>--max-samples</code> - Number of samples to generate (default: 1000)</li>\n",
        "        <li><code>--batch-size</code> - How many samples to generate at once (default: 100)</li>\n",
        "    </ul>\n",
        "    <p><b>Advanced options:</b> See the <a href=\"https://github.com/rhasspy/piper-sample-generator\">piper-sample-generator documentation</a> for additional parameters like:</p>\n",
        "    <ul>\n",
        "        <li><code>--noise-scale</code> - Controls voice variation (higher = more variation)</li>\n",
        "        <li><code>--noise-w</code> - Controls speaking style variation</li>\n",
        "        <li><code>--length-scale</code> - Controls speaking speed (higher = slower)</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-SvGtCCM9akR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d071f1-4a95-436e-9dfd-2cd965adaddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG:__main__:Loading /content/piper-sample-generator/models/en_US-libritts_r-medium.pt\n",
            "INFO:__main__:Successfully loaded the model\n",
            "DEBUG:__main__:CUDA available, using GPU\n",
            "DEBUG:__main__:Batch 1/10 complete\n",
            "DEBUG:__main__:Batch 2/10 complete\n",
            "DEBUG:__main__:Batch 3/10 complete\n",
            "DEBUG:__main__:Batch 4/10 complete\n",
            "DEBUG:__main__:Batch 5/10 complete\n",
            "DEBUG:__main__:Batch 6/10 complete\n",
            "DEBUG:__main__:Batch 7/10 complete\n",
            "DEBUG:__main__:Batch 8/10 complete\n",
            "DEBUG:__main__:Batch 9/10 complete\n",
            "DEBUG:__main__:Batch 10/10 complete\n",
            "INFO:__main__:Done\n"
          ]
        }
      ],
      "source": [
        "# Generates a larger amount of wake word samples.\n",
        "# Start here when trying to improve your model.\n",
        "# See https://github.com/rhasspy/piper-sample-generator for the full set of\n",
        "# parameters. In particular, experiment with noise-scales and noise-scale-ws,\n",
        "# generating negative samples similar to the wake word, and generating many more\n",
        "# wake word samples, possibly with different phonetic pronunciations.\n",
        "\n",
        "!python3 piper-sample-generator/generate_samples.py \"{target_word}\" \\\n",
        "--max-samples 1000 \\\n",
        "--batch-size 100 \\\n",
        "--output-dir generated_samples \\\n",
        "--model /content/piper-sample-generator/models/en_US-libritts_r-medium.pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_FWSjiB5R6v"
      },
      "source": [
        "## üéµ Step 3: Download Background Audio Data\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Downloads audio data for augmentation, including room impulse responses and background noise.</p>\n",
        "    <p><b>Expected time:</b> 10-20 minutes (this step can be slow!)</p>\n",
        "    <p><b>Why this matters:</b> Good background audio is essential for training a robust wake word model that works in real environments.</p>\n",
        "    <p><b>Note:</b> The data downloaded has mixed licenses and should be considered for <b>non-commercial personal use only</b>.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YJRG4Qvo9nXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770,
          "referenced_widgets": [
            "fb2abd1d89074428bad60a54874a7150",
            "da411a2e716745c9ba7274ac5a626cd3",
            "2eaed2586c7f40c4a2cd2248af777964",
            "ac6344c17dd444b5a77b7d3eb9ff38e9",
            "9eb9a6a3dec244fe9e70e8122f71bffd",
            "9dfff3759d9a445ca936ce2369c916d1",
            "8598a8cf5aaa4d5e80e0dd76c08ff044",
            "a9111979175f4d2f857d7596b1198e39",
            "1c47c5159dde4710ac2ccd644e432f56",
            "3e5ec96f4b55406ebc6e91e259e7bed3",
            "721f0766a01a4b80848296ebed52b976"
          ]
        },
        "outputId": "b07837fd-09f6-45e7-9e3e-2bb0b85496a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/270 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb2abd1d89074428bad60a54874a7150"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.6.0+cu124) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: libavutil.so.58: cannot open shared object file: No such file or directory\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: /usr/local/lib/python3.11/dist-packages/torchcodec/libtorchcodec_core4.so: undefined symbol: _ZNK3c106Device3strB5cxx11Ev\n[end of libtorchcodec loading traceback].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3962875147.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrir_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"davidscripka/MIT_environmental_impulse_responses\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreaming\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Save clips to 16-bit PCM wav files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrir_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'array'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m32767\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2359\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2361\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2362\u001b[0m             \u001b[0;31m# no need to format thanks to FormattedExamplesIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/iterable_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0;31m# feature casting (inc column addition) handled within self._iter_arrow()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_arrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_batch_to_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_batch\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mdecode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_batch\u001b[0;34m(self, batch, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m             decoded_batch[column_name] = (\n\u001b[0;32m-> 2142\u001b[0;31m                 [\n\u001b[0m\u001b[1;32m   2143\u001b[0m                     \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2141\u001b[0m             decoded_batch[column_name] = (\n\u001b[1;32m   2142\u001b[0m                 [\n\u001b[0;32m-> 2143\u001b[0;31m                     \u001b[0mdecode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode_example\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;31m# we pass the token to read and decode files from private repositories in streaming mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_per_repo_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/audio.py\u001b[0m in \u001b[0;36mdecode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTORCHCODEC_AVAILABLE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_torchcodec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"To support decoding audio data, please install 'torchcodec'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/features/_torchcodec.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchcodec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioDecoder\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_AudioDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAudioDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AudioDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# but that results in circular import.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrameBatch\u001b[0m  \u001b[0;31m# usort:skip # noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplers\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/decoders/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# LICENSE file in the root directory of this source tree.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioStreamMetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVideoStreamMetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_audio_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioDecoder\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_video_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoDecoder\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/_core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from ._metadata import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mAudioStreamMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mContainerMetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/_core/_metadata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from torchcodec._core.ops import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0m_get_container_json_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0m_get_stream_json_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/_core/ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mload_torchcodec_shared_libraries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcodec/_core/ops.py\u001b[0m in \u001b[0;36mload_torchcodec_shared_libraries\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n[end of libtorchcodec loading traceback].\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     )\n\u001b[0;32m---> 69\u001b[0;31m     raise RuntimeError(\n\u001b[0m\u001b[1;32m     70\u001b[0m         f\"\"\"Could not load libtorchcodec. Likely causes:\n\u001b[1;32m     71\u001b[0m           \u001b[0;36m1.\u001b[0m \u001b[0mFFmpeg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproperly\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myour\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mWe\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Could not load libtorchcodec. Likely causes:\n          1. FFmpeg is not properly installed in your environment. We support\n             versions 4, 5, 6 and 7.\n          2. The PyTorch version (2.6.0+cu124) is not compatible with\n             this version of TorchCodec. Refer to the version compatibility\n             table:\n             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n          3. Another runtime dependency; see exceptions below.\n        The following exceptions were raised as we tried to load libtorchcodec:\n        \n[start of libtorchcodec loading traceback]\nFFmpeg version 7: libavutil.so.59: cannot open shared object file: No such file or directory\nFFmpeg version 6: libavutil.so.58: cannot open shared object file: No such file or directory\nFFmpeg version 5: libavutil.so.57: cannot open shared object file: No such file or directory\nFFmpeg version 4: /usr/local/lib/python3.11/dist-packages/torchcodec/libtorchcodec_core4.so: undefined symbol: _ZNK3c106Device3strB5cxx11Ev\n[end of libtorchcodec loading traceback]."
          ]
        }
      ],
      "source": [
        "# Downloads audio data for augmentation. This can be slow!\n",
        "# Borrowed from openWakeWord's automatic_model_training.ipynb, accessed March 4, 2024\n",
        "#\n",
        "# **Important note!** The data downloaded here has a mixture of difference\n",
        "# licenses and usage restrictions. As such, any custom models trained with this\n",
        "# data should be considered as appropriate for **non-commercial** personal use only.\n",
        "\n",
        "\n",
        "import datasets\n",
        "import scipy\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "## Download MIR RIR data\n",
        "\n",
        "output_dir = \"./mit_rirs\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    rir_dataset = datasets.load_dataset(\"davidscripka/MIT_environmental_impulse_responses\", split=\"train\", streaming=True)\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    for row in tqdm(rir_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1]\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "## Download noise and background audio\n",
        "\n",
        "# Audioset Dataset (https://research.google.com/audioset/dataset/index.html)\n",
        "# Download one part of the audioset .tar files, extract, and convert to 16khz\n",
        "# For full-scale training, it's recommended to download the entire dataset from\n",
        "# https://huggingface.co/datasets/agkphysics/AudioSet, and\n",
        "# even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)\n",
        "\n",
        "if not os.path.exists(\"audioset\"):\n",
        "    os.mkdir(\"audioset\")\n",
        "\n",
        "    fname = \"bal_train09.tar\"\n",
        "    out_dir = f\"audioset/{fname}\"\n",
        "    link = \"https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/\" + fname\n",
        "    !wget -O {out_dir} {link}\n",
        "    !cd audioset && tar -xf bal_train09.tar\n",
        "\n",
        "    output_dir = \"./audioset_16k\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    audioset_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"audioset/audio\").glob(\"**/*.flac\")]})\n",
        "    audioset_dataset = audioset_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "    for row in tqdm(audioset_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".flac\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n",
        "\n",
        "# Free Music Archive dataset\n",
        "# https://github.com/mdeff/fma\n",
        "# (Third-party mchl914 extra small set)\n",
        "\n",
        "output_dir = \"./fma\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    fname = \"fma_xs.zip\"\n",
        "    link = \"https://huggingface.co/datasets/mchl914/fma_xsmall/resolve/main/\" + fname\n",
        "    out_dir = f\"fma/{fname}\"\n",
        "    !wget -O {out_dir} {link}\n",
        "    !cd {output_dir} && unzip -q {fname}\n",
        "\n",
        "    output_dir = \"./fma_16k\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.mkdir(output_dir)\n",
        "\n",
        "    # Save clips to 16-bit PCM wav files\n",
        "    fma_dataset = datasets.Dataset.from_dict({\"audio\": [str(i) for i in Path(\"fma/fma_small\").glob(\"**/*.mp3\")]})\n",
        "    fma_dataset = fma_dataset.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))\n",
        "    for row in tqdm(fma_dataset):\n",
        "        name = row['audio']['path'].split('/')[-1].replace(\".mp3\", \".wav\")\n",
        "        scipy.io.wavfile.write(os.path.join(output_dir, name), 16000, (row['audio']['array']*32767).astype(np.int16))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "168ScZnP5R6w"
      },
      "source": [
        "## üîÑ Step 4: Set Up Audio Augmentation\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Configures audio augmentation to create more varied training samples.</p>\n",
        "    <p><b>Why this matters:</b> Augmentation helps the model learn to recognize your wake word in different environments and conditions.</p>\n",
        "    <p><b>Key parameters to experiment with:</b></p>\n",
        "    <ul>\n",
        "        <li><code>augmentation_probabilities</code> - Chances of applying different audio effects</li>\n",
        "        <li><code>background_min_snr_db</code> and <code>background_max_snr_db</code> - Signal-to-noise ratio range</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW3bmbI5-JAz"
      },
      "outputs": [],
      "source": [
        "# Sets up the augmentations.\n",
        "# To improve your model, experiment with these settings and use more sources of\n",
        "# background clips.\n",
        "\n",
        "from microwakeword.audio.augmentation import Augmentation\n",
        "from microwakeword.audio.clips import Clips\n",
        "from microwakeword.audio.spectrograms import SpectrogramGeneration\n",
        "\n",
        "clips = Clips(input_directory='generated_samples',\n",
        "              file_pattern='*.wav',\n",
        "              max_clip_duration_s=None,\n",
        "              remove_silence=False,\n",
        "              random_split_seed=10,\n",
        "              split_count=0.1,\n",
        "              )\n",
        "augmenter = Augmentation(augmentation_duration_s=3.2,\n",
        "                         augmentation_probabilities = {\n",
        "                                \"SevenBandParametricEQ\": 0.1,\n",
        "                                \"TanhDistortion\": 0.1,\n",
        "                                \"PitchShift\": 0.1,\n",
        "                                \"BandStopFilter\": 0.1,\n",
        "                                \"AddColorNoise\": 0.1,\n",
        "                                \"AddBackgroundNoise\": 0.75,\n",
        "                                \"Gain\": 1.0,\n",
        "                                \"RIR\": 0.5,\n",
        "                            },\n",
        "                         impulse_paths = ['mit_rirs'],\n",
        "                         background_paths = ['fma_16k', 'audioset_16k'],\n",
        "                         background_min_snr_db = -5,\n",
        "                         background_max_snr_db = 10,\n",
        "                         min_jitter_s = 0.195,\n",
        "                         max_jitter_s = 0.205,\n",
        "                         )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqJknQ9g5R6w"
      },
      "source": [
        "### üîÑ Step 4.1: Test Audio Augmentation\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Augments a random clip and plays it back so you can verify the augmentation sounds reasonable.</p>\n",
        "    <p><b>What to listen for:</b> The wake word should still be recognizable despite background noise and effects.</p>\n",
        "    <p><b>Tip:</b> If the augmentation is too strong (wake word not audible) or too weak (no background noise), adjust the parameters in the previous cell.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5UsJfKKD1k9"
      },
      "outputs": [],
      "source": [
        "# Augment a random clip and play it back to verify it works well\n",
        "\n",
        "from IPython.display import Audio\n",
        "from microwakeword.audio.audio_utils import save_clip\n",
        "\n",
        "random_clip = clips.get_random_clip()\n",
        "augmented_clip = augmenter.augment_clip(random_clip)\n",
        "save_clip(augmented_clip, 'augmented_clip.wav')\n",
        "\n",
        "Audio(\"augmented_clip.wav\", autoplay=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deXsEE1u5R6w"
      },
      "source": [
        "## üîÑ Step 5: Generate Augmented Features\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Augments samples and saves training, validation, and testing sets.</p>\n",
        "    <p><b>Why this matters:</b> This creates the actual data that will be used to train the neural network.</p>\n",
        "    <p><b>Note:</b> The training set uses more repetition to help the model learn, while the testing set uses a streaming approach to better simulate real-world usage.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7BHcY1mEGbK"
      },
      "outputs": [],
      "source": [
        "# Augment samples and save the training, validation, and testing sets.\n",
        "# Validating and testing samples generated the same way can make the model\n",
        "# benchmark better than it performs in real-word use. Use real samples or TTS\n",
        "# samples generated with a different TTS engine to potentially get more accurate\n",
        "# benchmarks.\n",
        "\n",
        "import os\n",
        "from mmap_ninja.ragged import RaggedMmap\n",
        "\n",
        "output_dir = 'generated_augmented_features'\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "\n",
        "splits = [\"training\", \"validation\", \"testing\"]\n",
        "for split in splits:\n",
        "  out_dir = os.path.join(output_dir, split)\n",
        "  if not os.path.exists(out_dir):\n",
        "      os.mkdir(out_dir)\n",
        "\n",
        "\n",
        "  split_name = \"train\"\n",
        "  repetition = 2\n",
        "\n",
        "  spectrograms = SpectrogramGeneration(clips=clips,\n",
        "                                     augmenter=augmenter,\n",
        "                                     slide_frames=10,    # Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.\n",
        "                                     step_ms=10,\n",
        "                                     )\n",
        "  if split == \"validation\":\n",
        "    split_name = \"validation\"\n",
        "    repetition = 1\n",
        "  elif split == \"testing\":\n",
        "    split_name = \"test\"\n",
        "    repetition = 1\n",
        "    spectrograms = SpectrogramGeneration(clips=clips,\n",
        "                                     augmenter=augmenter,\n",
        "                                     slide_frames=1,    # The testing set uses the streaming version of the model, so no artificial repetition is necessary\n",
        "                                     step_ms=10,\n",
        "                                     )\n",
        "\n",
        "  RaggedMmap.from_generator(\n",
        "      out_dir=os.path.join(out_dir, 'wakeword_mmap'),\n",
        "      sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),\n",
        "      batch_size=100,\n",
        "      verbose=True,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhlZG7ta5R6x"
      },
      "source": [
        "## üì• Step 6: Download Negative Datasets\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Downloads pre-generated spectrogram features for various negative datasets.</p>\n",
        "    <p><b>Why this matters:</b> Negative samples help the model learn what is NOT your wake word, reducing false activations.</p>\n",
        "    <p><b>Datasets included:</b></p>\n",
        "    <ul>\n",
        "        <li><code>dinner_party</code> - Conversations in a dinner party setting</li>\n",
        "        <li><code>dinner_party_eval</code> - Separate evaluation set of dinner party audio</li>\n",
        "        <li><code>no_speech</code> - Environmental sounds without speech</li>\n",
        "        <li><code>speech</code> - Various speech samples</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pGuJDPyp3ax"
      },
      "outputs": [],
      "source": [
        "# Downloads pre-generated spectrogram features (made for microWakeWord in\n",
        "# particular) for various negative datasets. This can be slow!\n",
        "\n",
        "output_dir = './negative_datasets'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n",
        "    link_root = \"https://huggingface.co/datasets/kahrendt/microwakeword/resolve/main/\"\n",
        "    filenames = ['dinner_party.zip', 'dinner_party_eval.zip', 'no_speech.zip', 'speech.zip']\n",
        "    for fname in filenames:\n",
        "        link = link_root + fname\n",
        "\n",
        "        zip_path = f\"negative_datasets/{fname}\"\n",
        "        !wget -O {zip_path} {link}\n",
        "        !unzip -q {zip_path} -d {output_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvlmesaf5R6x"
      },
      "source": [
        "## ‚öôÔ∏è Step 7: Configure Training Parameters\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Creates a YAML configuration file that controls the training process.</p>\n",
        "    <p><b>Why this matters:</b> These hyperparameters can make a huge difference in model quality.</p>\n",
        "    <p><b>Key parameters to experiment with:</b></p>\n",
        "    <ul>\n",
        "        <li><code>sampling_weight</code> - Controls how often samples from each dataset are used in training</li>\n",
        "        <li><code>penalty_weight</code> - Controls how much incorrect predictions from each dataset are penalized</li>\n",
        "        <li><code>training_steps</code> - Number of training iterations (increase for potentially better models)</li>\n",
        "        <li><code>positive_class_weight</code> and <code>negative_class_weight</code> - Balance between false positives and false negatives</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii1A14GsGVQT"
      },
      "outputs": [],
      "source": [
        "# Save a yaml config that controls the training process\n",
        "# These hyperparamters can make a huge different in model quality.\n",
        "# Experiment with sampling and penalty weights and increasing the number of\n",
        "# training steps.\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "config = {}\n",
        "\n",
        "config[\"window_step_ms\"] = 10\n",
        "\n",
        "config[\"train_dir\"] = (\n",
        "    \"trained_models/wakeword\"\n",
        ")\n",
        "\n",
        "\n",
        "# Each feature_dir should have at least one of the following folders with this structure:\n",
        "#  training/\n",
        "#    ragged_mmap_folders_ending_in_mmap\n",
        "#  testing/\n",
        "#    ragged_mmap_folders_ending_in_mmap\n",
        "#  testing_ambient/\n",
        "#    ragged_mmap_folders_ending_in_mmap\n",
        "#  validation/\n",
        "#    ragged_mmap_folders_ending_in_mmap\n",
        "#  validation_ambient/\n",
        "#    ragged_mmap_folders_ending_in_mmap\n",
        "#\n",
        "#  sampling_weight: Weight for choosing a spectrogram from this set in the batch\n",
        "#  penalty_weight: Penalizing weight for incorrect predictions from this set\n",
        "#  truth: Boolean whether this set has positive samples or negative samples\n",
        "#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated\n",
        "#       - random: choose a random portion of the entire spectrogram - useful for long negative samples\n",
        "#       - truncate_start: remove the start of the spectrogram\n",
        "#       - truncate_end: remove the end of the spectrogram\n",
        "#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets\n",
        "\n",
        "config[\"features\"] = [\n",
        "    {\n",
        "        \"features_dir\": \"generated_augmented_features\",\n",
        "        \"sampling_weight\": 2.0,\n",
        "        \"penalty_weight\": 1.0,\n",
        "        \"truth\": True,\n",
        "        \"truncation_strategy\": \"truncate_start\",\n",
        "        \"type\": \"mmap\",\n",
        "    },\n",
        "    {\n",
        "        \"features_dir\": \"negative_datasets/speech\",\n",
        "        \"sampling_weight\": 10.0,\n",
        "        \"penalty_weight\": 1.0,\n",
        "        \"truth\": False,\n",
        "        \"truncation_strategy\": \"random\",\n",
        "        \"type\": \"mmap\",\n",
        "    },\n",
        "    {\n",
        "        \"features_dir\": \"negative_datasets/dinner_party\",\n",
        "        \"sampling_weight\": 10.0,\n",
        "        \"penalty_weight\": 1.0,\n",
        "        \"truth\": False,\n",
        "        \"truncation_strategy\": \"random\",\n",
        "        \"type\": \"mmap\",\n",
        "    },\n",
        "    {\n",
        "        \"features_dir\": \"negative_datasets/no_speech\",\n",
        "        \"sampling_weight\": 5.0,\n",
        "        \"penalty_weight\": 1.0,\n",
        "        \"truth\": False,\n",
        "        \"truncation_strategy\": \"random\",\n",
        "        \"type\": \"mmap\",\n",
        "    },\n",
        "    { # Only used for validation and testing\n",
        "        \"features_dir\": \"negative_datasets/dinner_party_eval\",\n",
        "        \"sampling_weight\": 0.0,\n",
        "        \"penalty_weight\": 1.0,\n",
        "        \"truth\": False,\n",
        "        \"truncation_strategy\": \"split\",\n",
        "        \"type\": \"mmap\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps\n",
        "config[\"training_steps\"] = [10000]\n",
        "\n",
        "# Penalizing weight for incorrect class predictions - lists that correspond to training steps\n",
        "config[\"positive_class_weight\"] = [1]\n",
        "config[\"negative_class_weight\"] = [20]\n",
        "\n",
        "config[\"learning_rates\"] = [\n",
        "    0.001,\n",
        "]  # Learning rates for Adam optimizer - list that corresponds to training steps\n",
        "config[\"batch_size\"] = 128\n",
        "\n",
        "config[\"time_mask_max_size\"] = [\n",
        "    0\n",
        "]  # SpecAugment - list that corresponds to training steps\n",
        "config[\"time_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
        "config[\"freq_mask_max_size\"] = [\n",
        "    0\n",
        "]  # SpecAugment - list that corresponds to training steps\n",
        "config[\"freq_mask_count\"] = [0]  # SpecAugment - list that corresponds to training steps\n",
        "\n",
        "config[\"eval_step_interval\"] = (\n",
        "    500  # Test the validation sets after every this many steps\n",
        ")\n",
        "config[\"clip_duration_ms\"] = (\n",
        "    1500  # Maximum length of wake word that the streaming model will accept\n",
        ")\n",
        "\n",
        "# The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization\n",
        "# Once the target has been met, it chooses the maximum of the maximization metric. Set 'minimization_metric' to None to only maximize\n",
        "# Available metrics:\n",
        "#   - \"loss\" - cross entropy error on validation set\n",
        "#   - \"accuracy\" - accuracy of validation set\n",
        "#   - \"recall\" - recall of validation set\n",
        "#   - \"precision\" - precision of validation set\n",
        "#   - \"false_positive_rate\" - false positive rate of validation set\n",
        "#   - \"false_negative_rate\" - false negative rate of validation set\n",
        "#   - \"ambient_false_positives\" - count of false positives from the split validation_ambient set\n",
        "#   - \"ambient_false_positives_per_hour\" - estimated number of false positives per hour on the split validation_ambient set\n",
        "config[\"target_minimization\"] = 0.9\n",
        "config[\"minimization_metric\"] = None  # Set to None to disable\n",
        "\n",
        "config[\"maximization_metric\"] = \"average_viable_recall\"\n",
        "\n",
        "with open(os.path.join(\"training_parameters.yaml\"), \"w\") as file:\n",
        "    documents = yaml.dump(config, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwsMeXNq5R6x"
      },
      "source": [
        "## üöÄ Step 8: Train the Model\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Trains the neural network model using the data and configuration from previous steps.</p>\n",
        "    <p><b>Expected time:</b> 30+ minutes (much faster with a GPU)</p>\n",
        "    <p><b>What to expect:</b> The training process will print progress updates. When finished, it will convert the model to a streaming version suitable for on-device detection.</p>\n",
        "    <p><b>Key parameters to modify:</b></p>\n",
        "    <ul>\n",
        "        <li><code>--train 1</code> - Set to 0 to only convert and test the best-weighted model without training</li>\n",
        "        <li>Neural network architecture parameters at the end of the command</li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoEXJBaiC9mf"
      },
      "outputs": [],
      "source": [
        "# Trains a model. When finished, it will quantize and convert the model to a\n",
        "# streaming version suitable for on-device detection.\n",
        "# It will resume if stopped, but it will start over at the configured training\n",
        "# steps in the yaml file.\n",
        "# Change --train 0 to only convert and test the best-weighted model.\n",
        "# On Google colab, it doesn't print the mini-batch results, so it may appear\n",
        "# stuck for several minutes! Additionally, it is very slow compared to training\n",
        "# on a local GPU.\n",
        "\n",
        "!python -m microwakeword.model_train_eval \\\n",
        "--training_config='training_parameters.yaml' \\\n",
        "--train 1 \\\n",
        "--restore_checkpoint 1 \\\n",
        "--test_tf_nonstreaming 0 \\\n",
        "--test_tflite_nonstreaming 0 \\\n",
        "--test_tflite_nonstreaming_quantized 0 \\\n",
        "--test_tflite_streaming 0 \\\n",
        "--test_tflite_streaming_quantized 1 \\\n",
        "--use_weights \"best_weights\" \\\n",
        "mixednet \\\n",
        "--pointwise_filters \"64,64,64,64\" \\\n",
        "--repeat_in_block  \"1, 1, 1, 1\" \\\n",
        "--mixconv_kernel_sizes '[5], [7,11], [9,15], [23]' \\\n",
        "--residual_connection \"0,0,0,0\" \\\n",
        "--first_conv_filters 32 \\\n",
        "--first_conv_kernel_size 5 \\\n",
        "--stride 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9buX_qL5R6y"
      },
      "source": [
        "## üì§ Step 9: Export the Model\n",
        "\n",
        "<div style=\"background-color: #e8f4f8; padding: 15px; border-radius: 10px; margin-bottom: 15px;\">\n",
        "    <p><b>What this step does:</b> Downloads the trained TFLite model file for use with ESPHome.</p>\n",
        "    <p><b>Next steps:</b></p>\n",
        "    <ol>\n",
        "        <li>Create a model manifest JSON file based on the training results</li>\n",
        "        <li>Adjust the probability threshold based on test results</li>\n",
        "        <li>Upload both files to your ESPHome device</li>\n",
        "    </ol>\n",
        "    <p><b>Resources:</b></p>\n",
        "    <ul>\n",
        "        <li><a href=\"https://esphome.io/components/micro_wake_word\">ESPHome documentation</a></li>\n",
        "        <li><a href=\"https://github.com/esphome/micro-wake-word-models/tree/main/models/v2\">Example model configurations</a></li>\n",
        "    </ul>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex_UIWvwtjAN"
      },
      "outputs": [],
      "source": [
        "# Downloads the tflite model file. To use on the device, you need to write a\n",
        "# Model JSON file. See https://esphome.io/components/micro_wake_word for the\n",
        "# documentation and\n",
        "# https://github.com/esphome/micro-wake-word-models/tree/main/models/v2 for\n",
        "# examples. Adjust the probability threshold based on the test results obtained\n",
        "# after training is finished. You may also need to increase the Tensor arena\n",
        "# model size if the model fails to load.\n",
        "\n",
        "import os\n",
        "\n",
        "# Get the model file path\n",
        "model_path = \"trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite\"\n",
        "\n",
        "# Check if running in a Jupyter environment\n",
        "try:\n",
        "    from google.colab import files\n",
        "    # If in Colab, use files.download\n",
        "    files.download(model_path)\n",
        "    print(f\"Model downloaded from {model_path}\")\n",
        "except ImportError:\n",
        "    # If not in Colab, just print the path\n",
        "    print(f\"\\nModel saved at: {os.path.abspath(model_path)}\")\n",
        "    print(\"\\nTo use this model with ESPHome:\")\n",
        "    print(\"1. Create a model manifest JSON file\")\n",
        "    print(\"2. Copy both files to your ESPHome configuration directory\")\n",
        "    print(\"3. Configure ESPHome to use the model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNWJrUHO5R6y"
      },
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "<div style=\"background-color: #dff0d8; padding: 15px; border-radius: 10px; border-left: 5px solid #3c763d; margin-bottom: 20px;\">\n",
        "    <h3 style=\"margin-top: 0; color: #3c763d;\">You've Successfully Trained a Wake Word Model!</h3>\n",
        "    <p>You've completed all the steps to train a custom wake word model with microWakeWord. Here's what you can do next:</p>\n",
        "    <ol>\n",
        "        <li><b>Test your model</b> - Try different probability thresholds to balance between detection rate and false positives</li>\n",
        "        <li><b>Experiment</b> - Try different training parameters to improve your model</li>\n",
        "        <li><b>Deploy to ESPHome</b> - Use your model on an ESP32 device</li>\n",
        "    </ol>\n",
        "    <p>Remember that wake word model training is an iterative process. You may need to adjust parameters and retrain several times to get the best results for your specific use case.</p>\n",
        "</div>\n",
        "\n",
        "### Example ESPHome Configuration\n",
        "\n",
        "```yaml\n",
        "# Wake word configuration\n",
        "micro_wake_word:\n",
        "  model_file: \"stream_state_internal_quant.tflite\"\n",
        "  model_name: \"my_wake_word\"\n",
        "  probability_cutoff: 0.5  # Adjust based on training results\n",
        "  \n",
        "binary_sensor:\n",
        "  - platform: micro_wake_word\n",
        "    name: \"Wake Word Detected\"\n",
        "    id: wake_word\n",
        "    model_id: my_wake_word\n",
        "    \n",
        "# Optional - add a text-to-speech response\n",
        "esphome:\n",
        "  on_boot:\n",
        "    priority: -100\n",
        "    then:\n",
        "      - delay: 5s\n",
        "      - logger.log: \"Wake word detection ready\"\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb2abd1d89074428bad60a54874a7150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da411a2e716745c9ba7274ac5a626cd3",
              "IPY_MODEL_2eaed2586c7f40c4a2cd2248af777964",
              "IPY_MODEL_ac6344c17dd444b5a77b7d3eb9ff38e9"
            ],
            "layout": "IPY_MODEL_9eb9a6a3dec244fe9e70e8122f71bffd"
          }
        },
        "da411a2e716745c9ba7274ac5a626cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dfff3759d9a445ca936ce2369c916d1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8598a8cf5aaa4d5e80e0dd76c08ff044",
            "value": "Resolving‚Äádata‚Äáfiles:‚Äá100%"
          }
        },
        "2eaed2586c7f40c4a2cd2248af777964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9111979175f4d2f857d7596b1198e39",
            "max": 270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c47c5159dde4710ac2ccd644e432f56",
            "value": 270
          }
        },
        "ac6344c17dd444b5a77b7d3eb9ff38e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e5ec96f4b55406ebc6e91e259e7bed3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_721f0766a01a4b80848296ebed52b976",
            "value": "‚Äá270/270‚Äá[00:00&lt;00:00,‚Äá‚Äá8.67it/s]"
          }
        },
        "9eb9a6a3dec244fe9e70e8122f71bffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dfff3759d9a445ca936ce2369c916d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8598a8cf5aaa4d5e80e0dd76c08ff044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9111979175f4d2f857d7596b1198e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c47c5159dde4710ac2ccd644e432f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e5ec96f4b55406ebc6e91e259e7bed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721f0766a01a4b80848296ebed52b976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}